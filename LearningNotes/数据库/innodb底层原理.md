# innodb底层原理

> 已有的存储引擎：InnoDB、MyISAM、Memory、CSV、Archive、Blackhole、Merge、Federated、Example
>
> 常用的存储引擎目前就只有InnoDB和MyISAM



## 内存架构

> 参考文档：https://www.cnblogs.com/detectiveHLH/p/13390380.html

InnoDB的内存架构主要分为三大块，**缓冲池**（Buffer Pool）、**重做缓冲池**（Redo Log Buffer）和**额外内存池**

### 缓冲池

InnoDB为了做数据的持久化，会将数据存储到磁盘上。但是面对大量的请求时，CPU的处理速度和磁盘的IO速度之间差距太大，为了提高整体的效率， InnoDB引入了**缓冲池**。

当有请求来查询数据时，如果缓存池中没有，就会去磁盘中查找，将匹配到的数据放入缓存池中。同样的，如果有请求来修改数据，MySQL并不会直接去修改磁盘，而是会修改已经在缓冲池的页中的数据，然后再将数据刷回磁盘，这就是缓冲池的作用，加速读，加速写，减少与磁盘的IO交互。

缓冲池说白了就是把磁盘中的数据丢到内存，那既然是内存就会存在没有内存空间可以分配的情况。所以缓冲池采用了**LRU**算法，在缓冲池中没有空闲的页时，来进行页的淘汰。但是采用这种算法会带来一个问题叫做**缓冲池污染**。

当你在进行批量扫描甚至全表扫描时，可能会将缓冲池中的热点页全部替换出去。这样以来可能会导致MySQL的性能断崖式下降。所以InnoDB对LRU做了一些优化，**规避了这个问题**。

MySQL采用**日志先行**，在真正写数据之前，会首先记录一个日志，叫**Redo Log**，会定期的使用CheckPoint技术将新的Redo Log刷入磁盘。



#### 插入缓冲

插入缓冲针对的操作是更新或者插入，我们考虑最坏的情况，那就是需要更新的数据都不在缓冲池中。那么此时会有下面两种方案。

1. 来一条数据就直接写入磁盘
2. 等数据达到某个阈值（例如50条）才批量的写入磁盘（较好）

> 由于insert buffer一开始只是对于插入有效，所以为了增强其功能，后来变成了change buffer。
>
> insertbuffer只针对insert有效，change buffering对insert、delete、update(delete+insert)、purge都有效

只对于**非聚集索引（非唯一）**的插入和更新有效，对于每一次的插入不是写到索引页中，而是先判断插入的非聚集索引页**是否在缓冲池**中，如果在则直接插入；若不在，则先放到Insert Buffer 中，再按照一定的频率进行合并操作，再写回disk。这样通常能将多个插入合并到一个操作中，目的还是为了减少随机IO带来性能损耗。（配合上**redoLog**可以实现一致性和持久化）

使用插入缓冲的条件：（因为涉及这两个索引就要回去数据库中查找是否重复）

- 非聚集索引
- 非唯一索引



#### 两次写（double write）

change buffer 和 double write 两个特性相辅相成的。

**插入缓冲**提高了MySQL的性能，而**两次写**则在此基础上提高了数据的可靠性。我们知道，当数据还在缓冲池中的时候，当机器宕机了，发生了**写失效**，有Redo Log来进行恢复。但是如果是在从缓冲池中将数据刷回磁盘的时候宕机了呢？

这种情况叫做部分写失效，此时重做日志就无法解决问题。

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/007S8ZIlgy1gghaq9msq9j30g00ae0tf.jpg)

在刷脏页时，并不是直接刷入磁盘，而是copy到内存中的Doublewrite Buffer中，然后再拷贝至磁盘共享表空间（你可以就理解为磁盘）中，每次写入1M，等copy完成后，再将Doublewrite Buffer中的页写入磁盘文件。

有了两次写机制，即使在刷脏页时宕机了，在实例恢复的时候也可以从共享表空间中找到Doublewrite Buffer的页副本，直接将其覆盖原来的数据页即可。



#### 自适应哈希索引

Adaptive Hash index属性使得InnoDB更像是内存数据库。

Innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热数据，建立哈希索引可以带来速度的提升

经常访问的二级索引数据会自动被生成到hash索引里面去(最近连续被访问三次的数据)，自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。
哈希（hash）是一种非常快的等值查找方法，在一般情况下这种查找的时间复杂度为O(1),即一般仅需要一次查找就能定位数据。而B+树的查找次数，取决于B+树的高度，在生产环境中，B+树的高度一般3-4层，故需要3-4次的查询。

innodb会监控对表上索引页的查询。如果观察到建立哈希索引可以带来速度提升，则自动建立哈希索引，称之为自适应哈希索引（Adaptive Hash Index，AHI）。
AHI有一个要求，就是**对这个页的连续访问模式必须是一样的**。



### 最小单位：页

**页**，是InnoDB中数据管理的最小单位。当我们查询数据时，其是以页为单位，将磁盘中的数据加载到缓冲池中的。同理，更新数据也是以页为单位，将我们对数据的修改刷回磁盘。每页的默认大小为16k，每页中包含了若干行的数据，页的结构如下图所示。

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/007S8ZIlgy1ggh1l3wn05j30ab08d0t5.jpg)

每一页的数据，可以通过**FileHeader**中的上一页和下一页的数据，页与页之间可以形成**双向链表**。因为在实际的物理存储上，数据并不是连续存储的。你可以把他理解成G1的Region在内存中的分布。

而一页中所包含的**行数据**，行与行之间则形成了**单向链表**。我们存入的行数据最终会到**User Records**中，当然最初User Records并不占据任何存储空间。随着我们存入的数据越来越多，**User Records**会越来越大，**Free Space**的空间会越来越小，直到被占用完，就会申请新的数据页。

User Records中的数据，是按照主键id来进行排序的，当我们按照主键来进行查找时，会沿着这个单向链表一直往后找。



### 重做日志缓冲

当事务开始时，会先记录Redo Log到Redo Log Buffer中，然后再更新缓冲池页数据。

Redo Log Buffer中的数据会按照一定的频率写到重做日志中去。被更改过的页就会被标记成**脏页**，InnoDB会根据CheckPoint机制来将脏页刷到磁盘。



#### MySQL日志

MySQL的日志可以分为错误日志、二进制文件、查询日志和满查询日志。

- **错误日志** 很好理解，就是服务运行过程中发生的严重错误日志。当我们的数据库无法启动时，就可以来这里看看具体不能启动的原因是什么
- **二进制文件** 它有另外一个名字你应该熟悉，叫**Binlog**，其记录了对数据库所有的更改。
- **查询日志** 记录了来自客户端的所有语句
- **慢查询日志** 这里记录了所有响应时间超过阈值的SQL语句，这个阈值我们可以自己设置，参数为`long_query_time`，其默认值为10s，且默认是**关闭**的状态，需要手动的打开。



#### innodb日志

InnoDB日志就只有两种，Redo Log和Undo Log，

- **Redo Log** 重做日志，用于记录事务操作的变化，且记录的是修改之后的值。不管事务是否提交都会记录下来。例如在更新数据时，会先将更新的记录写到Redo Log中，再更新缓存中页中的数据。然后按照设置的更新策略，将内存中的数据刷回磁盘。
- **Undo Log** 记录的是记录的事务开始之前的一个版本，可用于事务失败之后发生的回滚。

Redo Log记录的是具体某个数据页上的修改，只能在当前Server使用，而Binlog可以理解为可以给其他类型的存储引擎使用。这也是Binlog的一个重要作用，那就是**主从复制**，另外一个作用是**数据恢复**。

上面提到过，Binlog中记录了所有对数据库的修改，其记录日志有三种格式。分别是Statement、Row和MixedLevel。

- **Statement** 记录所有会修改数据的SQL，其只会记录SQL，并不需要记录下这个SQL影响的所有行，**减少了日志量**，提高了性能。但是由于只是记录执行语句，不能保证在Slave节点上能够正确执行，所以还需要额外的记录一些上下文信息
- **Row** 只保存被修改的记录，与Statement只记录执行SQL来比较，Row会产生大量的日志。但是Row不用记录上下文信息了，只需要关注被改成啥样就行。
- **MixedLevel** 就是Statement和Row混合使用。

具体使用哪种日志，需要根据实际情况来决定。例如一条UPDATE语句更新了很多的数据，采用Statement会更加节省空间，但是相对的，Row会更加的可靠。



### InnoDB和MyISAM的区别

- **事务** InnoDB支持事务、回滚、事务安全和奔溃恢复。而MyISAM不支持，但查询的速度要比InnoDB更快
- **主键** InnoDB规定，如果没有设置主键，就自动的生成一个6字节的主键，而MyISAM允许没有任何索引和主键的存在，索引就是行的地址
- **外键** InnoDB支持外键，而MyISAM不支持
- **表锁** InnoDB支持**行锁**和**表锁**，而MyISAM只支持表锁
- **全文索引** InnoDB不支持全文索引，但是可以用插件来实现相应的功能，而MyISAM是本身就支持全本索引
- **行数** InnoDB获取行数时，需要扫全表。而MyISAM保存了当前表的总行数，直接读取即可。

> 总结一下，MyISAM只适用于查询大于更新的场景，如果你的系统查询的情况占绝大多数（例如报表系统）就可以使用MyISAM来存储，除此之外，都建议使用InnoDB。



## 索引结构

> 参考文档：https://blog.csdn.net/zhou_p/article/details/105727750，https://blog.csdn.net/liuzewei2015/article/details/99699015

### 索引底层结构选型

#### 哈希表

哈希表是做数据快速检索的有效利器。

哈希算法：也叫散列算法，就是把任意值(key)通过哈希函数变换为固定长度的 key 地址，通过这个地址进行具体数据的数据结构。

**select \* from user where id=7;** 

哈希算法首先计算存储 id=7 的数据的物理地址 addr=hash(7)=4231，而 4231 映射的物理地址是 0x77，0x77 就是 id=7 存储的额数据的物理地址，通过该独立地址可以找到对应 user_name='g'这个数据。这就是哈希算法快速检索数据的计算过程。

但是哈希算法有个数据碰撞的问题，也就是哈希函数可能对不同的 key 会计算出同一个结果，比如 hash(7)可能跟 hash(199)计算出来的结果一样，也就是不同的 key 映射到同一个结果了，这就是碰撞问题。解决碰撞问题的一个常见处理方式就是链地址法，即用链表把碰撞的数据接连起来。计算哈希值之后，还需要检查该哈希值是否存在碰撞数据链表，有则一直遍历到链表尾，直达找到真正的 key 对应的数据为止。

从算法时间复杂度分析来看，哈希算法时间复杂度为 O（1），检索速度非常快。比如查找 id=7 的数据，哈希索引只需要计算一次就可以获取到对应的数据，检索速度非常快。

但是范围查找：**select \* from user where id \>3**

针对以上这个语句，我们希望做的是找出 id>3 的数据，这是很典型的范围查找。如果使用哈希算法实现的索引，范围查找怎么做呢？一个简单的思路就是一次把所有数据找出来加载到内存，然后再在内存里筛选筛选目标范围内的数据。但是这个范围查找的方法也太笨重了，没有一点效率而言。

所以，使用哈希算法实现的索引虽然可以做到快速检索数据，但是没办法做数据高效范围查找，因此哈希索引是不适合作为 Mysql 的底层索引的数据结构。



#### 二叉查找树(BST)

二叉查找树的时间复杂度是 O(lgn)，比如针对上面这个二叉树结构，我们需要计算比较 3 次就可以检索到 id=7 的数据，相对于直接遍历查询省了一半的时间，从检索效率上看来是能做到高速检索的。此外二叉树的结构能不能解决哈希索引不能提供的范围查找功能呢？

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/aHR0cHM6Ly9zMi41MWN0by5jb20vb3NzLzIwMjAwMy8yNi8zZTNmNzhjMDExNjlhZTJhYjRjMWI2ODRiYzYxYWY2Yy5qcGc.jpg)

答案是可以的。观察上面的图，二叉树的叶子节点都是按序排列的，从左到右依次升序排列，如果我们需要找 id>5 的数据，那我们取出节点为 6 的节点以及其右子树就可以了，范围查找也算是比较容易实现。

但是普通的二叉查找树有个致命缺点：极端情况下会退化为线性链表，二分查找也会退化为遍历查找，时间复杂退化为 O（N），检索性能急剧下降。比如以下这个情况，二叉树已经极度不平衡了，已经退化为链表了，检索速度大大降低。此时检索 id=7 的数据的所需要计算的次数已经变为 7 了。

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/aHR0cHM6Ly9zNS41MWN0by5jb20vb3NzLzIwMjAwMy8yNi9hYmYwOGQwNzE0YWQxNzAxMTQzMzIyZTNiMzU0MjU2ZS5qcGc.jpg)

在数据库中，数据的自增是一个很常见的形式，比如一个表的主键是 id，而主键一般默认都是自增的，如果采取二叉树这种数据结构作为索引，那上面介绍到的不平衡状态导致的线性查找的问题必然出现。因此，简单的二叉查找树存在不平衡导致的检索性能降低的问题，是不能直接用于实现 Mysql 底层索引的。



####  AVL 树和红黑树

> 通过树节点的自动旋转和调整，让二叉树始终保持基本平衡的状态，就能保持二叉查找树的最佳查找性能了。基于这种思路的自调整平衡状态的二叉树有 AVL 树和红黑树。

平衡二叉树是保持任意结点的子树高度差不大于一的二叉搜索树，拥有良好的查找性能。

红黑树其实不算是标准的平衡二叉树，但是可以保持相对的平衡。为了应对经常插入删除而导致的自旋改变次数太多，引入红黑两种颜色的的结点，保持另一种状态的相对平衡。但是在递增时候也会有相对的右倾趋势。

数据库查询数据的瓶颈在于磁盘 IO，如果使用的是 AVL 树，我们每一个树节点只存储了一个数据，我们一次磁盘 IO 只能取出来一个节点上的数据加载到内存里，那比如查询 id=7 这个数据我们就要进行磁盘 IO 三次，这是多么消耗时间的。所以我们设计数据库索引时需要首先考虑怎么尽可能减少磁盘 IO 的次数。

磁盘 IO 有个有个特点，就是从磁盘读取 1B 数据和 1KB 数据所消耗的时间是基本一样的，我们就可以根据这个思路，我们可以在一个树节点上尽可能多地存储数据，一次磁盘 IO 就多加载点数据到内存，这就是 B 树，B+树的的设计原理了。



#### B树

![](https://gitee.com/wextree/Wex_imgs/raw/master/img/20170717203847019.png)

其实**B树**可以看做一个**多叉的查找树**，二叉查找树的比较次数和查找效率都是很好的。

但是我们考虑IO磁盘的影响。它相对于内存来说十分慢的。

当数据量特别大的时候，就不能把整个索引树加载到磁盘中，而是加载每一个**磁盘页**，对应就是**树的结点**。

而访问的次数对于树来说其实就是**树的深度**，所以我们要让树尽量矮平，而**“胖矮”**就是B树的特点。

- 一个**M阶**的B树具有如下**几个特征**：

1. 定义任意非叶子结点最**多只有M个儿子**，且M>2；
2. 根结点的儿子数为[2, M]；
3. 除根结点以外的非叶子结点的**儿子数为[M/2, M]**，向上取整；
4. 非叶子结点的**关键字个数=儿子数-1**；
5. 所有**叶子结点位于同一层**；
6. **k个关键字把节点拆成k+1段**，分别指向k+1个儿子，同时满足查找树的大小关系。

- 有关b树的一些特性，注意**与后面的B+树区分**：

1. **关键字集合分布在整颗树中**；
2. 任何一个关键字**出现且只出现在一个结点中**；
3. 搜索有可能**在非叶子结点结束**；
4. 其搜索性能等价于在关键字**全集内做一次二分查找**；



#### B+树

![](https://gitee.com/wextree/Wex_imgs/raw/master/img/20170717205509476.png)

- **特征：**
  1. 有n棵子树的非叶子结点中含有**n个关键字**（b树是n-1个），这些关键字**不保存数据**，**只用来索引**，所有数据都保存在叶子节点（b树是每个关键字都保存数据）。
  2. 所有的**叶子结点中包含了全部关键字**的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小**自小而大顺序**链接。
  3. 所有的非叶子结点可以看成是索引部分，**结点中仅含其子树中的最大（或最小）关键字**。
  4. 通常在b+树上有**两个头指针**，一个**指向根结点**，一个**指向关键字最小的叶子结点**。
  5. 同一个数字会在不同节点中重复出现，**根节点的最大元素就是b+树的最大元素**。
- b+树相比于b树的**查询优势**：
  1. b+树的**中间节点不保存数据**，所以磁盘页能容纳更多节点元素，**更“矮胖”**；
  2. b+树查询**必须查找到叶子节点**，b树只要匹配到即可不用管元素位置，因此b+树**查找更稳定**（并不慢）；
  3. 对于**范围查找**来说，**b+树只需遍历叶子节点链表即可**，b树却需要重复地中序遍历。



### 引擎的具体实现

Mysql 底层数据引擎以插件形式设计，最常见的是 Innodb 引擎和 Myisam 引擎，用户可以根据个人需求选择不同的引擎作为 Mysql 数据表的底层引擎。

两个引擎数据和索引的组织方式是不一样的。

**Innodb 创建表后生成的文件有**：

-  frm:创建表的语句
-  idb:表里面的数据+索引文件



**Myisam 创建表后生成的文件有**：

-  frm:创建表的语句
-  MYD:表里面的数据文件（myisam data）
-  MYI:表里面的索引文件（myisam index）

从生成的文件看来，这两个引擎底层数据和索引的组织方式并不一样，MyISAM 引擎把数据和索引分开了，一人一个文件，这叫做非聚集索引方式；Innodb 引擎把数据和索引放在同一个文件里了，这叫做聚集索引方式。下面将从底层实现角度分析这两个引擎是怎么依靠 B+树这个数据结构来组织引擎实现的。



#### MyISAM 引擎的底层实现（非聚集索引方式）

MyISAM 用的是非聚集索引方式，即数据和索引落在不同的两个文件上。MyISAM 在建表时以主键作为 KEY 来建立主索引 B+树，树的叶子节点存的是对应数据的物理地址。我们拿到这个物理地址后，就可以到 MyISAM 数据文件中直接定位到具体的数据记录了。

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/aHR0cHM6Ly9zNC41MWN0by5jb20vb3NzLzIwMjAwMy8yNi9hMGMwZjFiNWY4MWE5YzEyNzFkOTU2NzNmNDgzNzMzYy5qcGc.jpg)

当我们为某个字段添加索引时，我们同样会生成对应字段的索引树，该字段的索引树的叶子节点同样是记录了对应数据的物理地址，然后也是拿着这个物理地址去数据文件里定位到具体的数据记录。



####  Innodb 引擎的底层实现（聚集索引方式）

InnoDB 是聚集索引方式，因此数据和索引都存储在同一个文件里。

以主键为key建立B+树，然后把主键所关联的内容数据放在那个结点里面，当你查询到id对应的结点时候，就直接取出数据，而不需要再去其他地方找。

但是如果是二级索引，也就是辅助索引或者是其他的普通索引，那么就会以你建立索引的那一列作为key建立B+树，然后对应结点的数据是key，然后如果还需要其他数据，那么就要利用这个key从主键索引中去查找对应的值。

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/20200424115617663.jpg)

问题来了，为什么 InnoDB 只在主键索引树的叶子节点存储了具体数据，但是其他索引树却不存具体数据呢，而要多此一举先找到主键，再在主键索引树找到对应的数据呢?

其实很简单，因为 InnoDB 需要节省存储空间。一个表里可能有很多个索引，InnoDB 都会给每个加了索引的字段生成索引树，如果每个字段的索引树都存储了具体数据，那么这个表的索引数据文件就变得非常巨大（数据极度冗余了）。从节约磁盘空间的角度来说，真的没有必要每个字段索引树都存具体数据，通过这种看似“多此一举”的步骤，在牺牲较少查询的性能下节省了巨大的磁盘空间，这是非常有值得的。

在进行 InnoDB 和 MyISAM 特点对比时谈到，MyISAM 查询性能更好，从上面索引文件数据文件的设计来看也可以看出原因：MyISAM 直接找到物理地址后就可以直接定位到数据记录，但是 InnoDB 查询到叶子节点后，还需要再查询一次主键索引树，才可以定位到具体数据。等于 MyISAM 一步就查到了数据，但是 InnoDB 要两步，那当然 MyISAM 查询性能更高。



### 索引其他底层知识

#### 局部性原理与磁盘预读

为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，**预读可以提高I/O效率**。预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。



#### 组合索引（联合索引）

指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循**最左前缀原则**

比如，我们在（a,b,c）字段上创建一个联合索引，则索引记录会首先按照A字段排序，然后再按照B字段排序然后再是C字段，因此，联合索引的特点就是：

1. 第一个字段一定是有序的
2. 当第一个字段值相等的时候，第二个字段又是有序的，依次类推。

```mysql
select * from table where a=1；
select * from table where a=1 and b=2；
select * from table where a=1 and b=2 and c=3；
```

上面三个查询按照 `（a ）, （a，b ）,（a，b，c ）`的顺序都可以利用到索引，这就是最左前缀匹配。

如果查询语句是：

```mysql
select * from table where a=1 and c=3； 
```

那么只会用到索引a。

如果查询语句是：

```mysql
select * from table where b=2 and c=3； 
```

因为没有用到最左前缀a，所以这个查询是用不到索引的。

如果用到了最左前缀而只是颠倒了顺序，也是可以用到索引的，因为mysql查询优化器会判断纠正这条sql语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。但我们还是最好按照索引顺序来查询，这样查询优化器就不用重新编译了。

```mysql
select * from table where b=2 and a=1；
select * from table where b=2 and a=1 and c=3；
```



#### 最左匹配原则

顾名思义：最左优先，以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(>、<、between、like)就会停止匹配。

即如果建立（a， b）的复合索引，只有当a匹配上的时候，才会匹配到b的索引。

因为mysql是这样建立（a， b）的复合索引的。

- 首先以a列建立B+数索引，然后将b列按顺序加上去。
- 所以其实查找条件`where a = x and b = y`时，是先找到a的结点位置，然后进行**索引下推**，找到匹配b的结点。

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/20200910005504881.png)



#### 外键

> 外键的定义：表的外键是另一张表的主键。将两张表联系到一起。
>
> 作用：简单的说是为了保证数据的完整性与一致性。
>
> **主键和索引**是不可少的，不仅可以优化数据检索速度，开发人员还省下其它的工作；**外键考虑**有两个问题：一个是如何保证数据库数据的完整性和一致性；二是第一条对性能的影响。

**外键的要求：**

1. 父表（student）与子表(sc_class)必须具有相同的存储引擎，而且禁用使用临时表
2. 数据表的存储引擎必须为**InnoDB**
3. 外键列与参照列必须具有相似的数据类型，其中数字的长度或有无符号位必须相同，而字符的长度可以不同。
4. 外键列和参照列必须创建索引，如果外键列不存在索引，mysql会自动创建索引。

**优势：**

1. 由数据库自身保证数据**一致性，完整性**，更可靠，因为程序很难100％保证数据的完整性，而用外键即使在数据库服务器当机或者出现其他问题的时候，也能够最大限度的保证数据的一致性和完整性。
2. 有主外键的数据库设计可以增加**ER图的可读性**，这点在数据库设计时非常重要。 3、外键在一定程度上说明的**业务逻辑**，会使设计周到具体全面。

**劣势：**

1. 可以用触发器或应用程序**保证**数据的完整性
2. 过分强调或者说使用主键／外键会平添**开发难度**，导致表过多等问题
3. 不用外键时数据**管理简单，操作方便，性能高**（导入导出等操作，在insert, update, delete 数据的时候更快）

**外键的性能问题：**

1. 数据库需要维护外键的内部管理；
2. 外键等于把数据的一致性事务实现，全部交给数据库服务器完成；
3. 有了外键，当做一些涉及外键字段的增，删，更新操作之后，需要触发相关操作去检查，而不得不消耗资源；
4. 外键还会因为需要请求对其他表内部加锁而容易出现死锁情况；



## 事务实现

> 参考文档：jianshu.com/p/9b83ea78b380

事务具有ACID四个特性：**原子性，一致性，隔离性，持久性。**

ACD三个特性是通过Redo log（重做日志）和Undo log 实现的。 而隔离性是通过锁来实现的。

### Redo log

重做日志用来实现事务的持久性，即D特性。它由两部分组成：

1. 内存中的重做日志缓冲
2. 重做日志文件





















































