# 数据库

## Redis

### Redis数据类型

- **五种基本类型：**字符串，哈希，列表，集合，有序集合
- **扩展类型：**pipeline, hyperloglog, geo



### 为什么要用Redis而不用map做缓存?

- 缓存分为**本地缓存**和**分布式缓存**。
  - **map就是本地缓存**，生命周期**随着JVM的销毁而结束**。如果创建多个实例，每个实例都会**各自存着一份缓存**，具有**不一致性**。
  - **Redis是分布式缓存**，多个实例**共用一份缓存**，缓存具有**一致性**。
- Redis可以**用比较大的空间**来做缓存，但是map由于JVM的局限性，所以一般**内存比较小**。
- Redis可以进行**持久化**，但是map**存在于内存**，一重启就没了。
- Redis有**过期机制**，而且有**丰富的API**进行操作，而map没有过期机制，而且API也比较少。



### Redis持久化的具体实现方式

- **RDB**

  - 通过配置自动进行的持久化

    ```
    save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。
    save 300 10            	#在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。
    save 60 10000        	#在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照
    ```

  - 通过save与bgsave命令进行持久化

  - 通过执行flushall命令，会清空内存数据并且触发一次持久化

  - 设置了主从复制，在复制的时候会进行一次快照

- **AOF**

  - 通过appendonly参数启用：appendonly yes (默认不开启，开启后默认30秒更新)

    ```
    	appendfsync always     #每次有数据修改发生时都会写入AOF文件。
    
        appendfsync everysec  #每秒钟同步一次，该策略为AOF的缺省策略。
    
        appendfsync no          #从不同步。高效但是数据不会被持久化
    ```



### 缓存处理流程

前台请求，后台先从缓存中取数据，取到直接返回结果，取不到时从数据库中取，数据库取到更新缓存，并返回结果，数据库也没取到，那直接返回空结果。

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/20180919143214712.png)









### 缓存雪崩（缓存击穿）

如果缓存数据**设置的过期时间是相同**的，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存**同时失效**，全部请求到数据库中。

- **Redis挂掉**了，请求全部走数据库。
- 对缓存数据**设置相同的过期时间**，导致某段时间内缓存失效，请求**全部走数据库**。

**解决：**

1. 在缓存的时候给过期时间加上一个**随机值**，这样就会大幅度的**减少缓存在同一时间过期**。
2. 事发前：实现Redis的**高可用**(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。
3. 事发中：万一Redis真的挂了，我们可以设置**本地缓存(eh-cache)+限流(hystrix)**，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)
4. 事发后：Redis持久化，重启后自动从磁盘上加载数据，**快速恢复缓存数据**。



**也可以加上互斥锁：**

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/20180919143214879.png)





### 缓存穿透

缓存穿透是指查询一个一定**不存在的数据**。由于缓存不命中，并且出于容错考虑，如果从**数据库查不到数据则不写入缓存**，这将导致这个不存在的数据**每次请求都要到数据库去查询**，失去了缓存的意义。

**解决：**

- 由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter**提前拦截**，不合法就不让这个请求到数据库层！

- 当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存里边去**。下次再请求的时候，就可以从缓存里边获取了。

- 这种情况我们一般会将空对象设置一个**较短的过期时间**。



### 缓存和数据库双写一致

一般来说，执行**更新操作**时，我们会有两种选择：

- 先操作数据库，再操作缓存
- 先操作缓存，再操作数据库
- 这**两个操作要么同时成功，要么同时失败**。所以，这会演变成一个**分布式事务**的问题。







## MySQL（关系数据库）

### 数据库索引

#### 快的原因

数据库的基本存储单位是页，很多页通过双向链表连接起来，内部用单项链表连接。如果没有索引的话，查找的方式是遍历双向链表然后找到对应的页。但是如果是有索引，使用的是B+树结构，可以在log N下查找到对应的页，所以使用起来非常快速。

####  种类

- **列的种类：**
  - **单列索引**，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。
  - **组合索引**，即一个索包含多个列
- **索引类型：**
  - **普通索引**，这是最基本的索引，它没有任何限制。
  - **唯一索引**，它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。
  - **主键索引**，它是一种特殊的唯一索引，不允许有空值。一般是在建表的时候同时创建主键索引。
  - **组合索引**，为了形象地对比单列索引和组合索引，为表添加多个字段

#### tips

如果分别在 username，city，age上建立单列索引，让该表有3个单列索引，查询时和上述的组合索引效率也会大不一样，**远远低于我们的组合索引**。虽然此时有了三个索引，但**Mysql只能用到其中的那个它认为似乎是最有效率的单列索引**。

建立这样的组合索引，其实是相当于分别建立了下面三组组合索引：

- username,city,age  

- username,city  

- username  

为什么没有 city，age这样的组合索引呢？这是因为Mysql组合索引**“最左前缀”**的结果。简单的理解就是只从最左面的开始组合。并不是只要包含这三列的查询都会用到该组合索引.

```mysql
-- 下面的几个SQL就会用到这个组合索引：
SELECT * FROM mytable WHREE username="admin" AND city="郑州" 
SELECT * FROM mytable WHREE username="admin"

-- 而下面几个则不会用到：
SELECT * FROM mytable WHREE age=20 AND city="郑州" 
SELECT * FROM mytable WHREE city="郑州"
```

#### 索引不足之处

- 虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行**INSERT、UPDATE和DELETE**。因为更新表时，Mysql不仅要保存数据，还要保存一下索引文件。

- 建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快。

#### 索引注意事项

- **索引不会包含有NULL值的列**

只要列中包含有NULL值都将不会被包含在索引中，**复合索引中只要有一列含有NULL值**，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL。

- **使用短索引**

对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个CHAR(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。

- **索引列排序**

Mysql查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。

- **like语句操作**

一般情况下不鼓励使用like操作，如果非使用不可，如何使用也是一个问题。like “%AAA%” 不会使用索引而like “AAA%”可以使用索引。

- **不要在列上进行运算**



### B树索引

![](https://gitee.com/wextree/Wex_imgs/raw/master/img/20170717203847019.png)

其实**B树**可以看做一个**多叉的查找树**，二叉查找树的比较次数和查找效率都是很好的。

但是我们考虑IO磁盘的影响。它相对于内存来说十分慢的。

当数据量特别大的时候，就不能把整个索引树加载到磁盘中，而是加载每一个**磁盘页**，对应就是**树的结点**。

而访问的次数对于树来说其实就是**树的深度**，所以我们要让树尽量矮平，而**“胖矮”**就是B树的特点。

- 一个**M阶**的B树具有如下**几个特征**：

1. 定义任意非叶子结点最**多只有M个儿子**，且M>2；
2. 根结点的儿子数为[2, M]；
3. 除根结点以外的非叶子结点的**儿子数为[M/2, M]**，向上取整；
4. 非叶子结点的**关键字个数=儿子数-1**；
5. 所有**叶子结点位于同一层**；
6. **k个关键字把节点拆成k+1段**，分别指向k+1个儿子，同时满足查找树的大小关系。

- 有关b树的一些特性，注意**与后面的B+树区分**：

1. **关键字集合分布在整颗树中**；
2. 任何一个关键字**出现且只出现在一个结点中**；
3. 搜索有可能**在非叶子结点结束**；
4. 其搜索性能等价于在关键字**全集内做一次二分查找**；



### B+树

![](https://gitee.com/wextree/Wex_imgs/raw/master/img/20170717205509476.png)

- **特征：**
  1. 有n棵子树的非叶子结点中含有**n个关键字**（b树是n-1个），这些关键字**不保存数据**，**只用来索引**，所有数据都保存在叶子节点（b树是每个关键字都保存数据）。
  2. 所有的**叶子结点中包含了全部关键字**的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小**自小而大顺序**链接。
  3. 所有的非叶子结点可以看成是索引部分，**结点中仅含其子树中的最大（或最小）关键字**。
  4. 通常在b+树上有**两个头指针**，一个**指向根结点**，一个**指向关键字最小的叶子结点**。
  5. 同一个数字会在不同节点中重复出现，**根节点的最大元素就是b+树的最大元素**。
- b+树相比于b树的**查询优势**：
  1. b+树的**中间节点不保存数据**，所以磁盘页能容纳更多节点元素，**更“矮胖”**；
  2. b+树查询**必须查找到叶子节点**，b树只要匹配到即可不用管元素位置，因此b+树**查找更稳定**（并不慢）；
  3. 对于**范围查找**来说，**b+树只需遍历叶子节点链表即可**，b树却需要重复地中序遍历。



### 哈希索引的特点（innodb是自适应哈希，干预不了）

- 根据哈希进行定位，可以非常快速定位到位置
- 无法利用索引进行排序
- 无法进行范围查询
- 无法进行最左匹配
- 具有大量重复键值问题，也就是哈希碰撞问题



### log

#### binlog

- **binlog**简单来说记录着每条变更的sql语句，当然还有事务id和时间等。
- **binlog**在事务提交的时候才记录。
- 当数据库表结构或表数据变更时，就会被记录，但是select不会，记录的是一种逻辑变化。
- 主要有**两个作用：**复制和恢复数据
  - 一主多从中，保持数据的一致性就是通过binlog进行的
  - 数据库发生故障时，也可以用binlog进行恢复



#### redolog

- **redolog**记录的是某个页做了什么修改，是物理变化。
- **redolog**在事务的开始就进行记录，先写commit。

- 数据库写数据是先写入内存，再刷入硬盘，但是为了避免频繁的进行IO，会先写入redolog。
- **redolog**也有一个**buffer**，当缓存满了的时候再一次性刷入内存。
- 也是要写内存的，但是它是顺序IO，比较快。
- **redolog**是为了持久化而生的。



#### **两阶段提交**来保证`redo log`和`binlog`的数据是一致的

1. 先进行**redolog**写盘，此时innodb事务进入**prepare**状态。
2. **binlog**开始写盘，此时innodb事务进入**commit**状态。
3. 每个**binlog**的结尾，都要加入XID event，标志着事务是否提交成功，也就是说，在这个标志之后，都是无效的。



#### undolog

- 也是逻辑日志，主要是进行事务的回滚。
- 记录的是相反的记录，比如插入，就记录删除，更新就记录相反的更新操作。
- 多版本控制：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。



### MVCC

> 英文全称为Multi-Version Concurrency Control,翻译为中文即 多版本并发控制
>
> **MVCC主要适用于Mysql的RC,RR隔离级别**



#### 基本原理

MVCC的实现，通过保存数据在**某个时间点的快照**来实现的。这意味着一个事务无论运行多长时间，在同一个事务里能够看到数据一致的视图。

根据事务开始的时间不同，同时也意味着在同一个时刻不同事务看到的相同表里的数据可能是不同的。



#### 基本特征

- 每行数据都存在一个版本，每次数据更新时都更新该版本。
- 修改时Copy出当前版本随意修改，各个事务之间无干扰。
- 保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback）



#### InnoDB存储引擎MVCC的实现策略

在每一行数据中额外保存**两个隐藏的列**：当前行**创建时的版本号和删除时的版本号**（可能为空，其实还有一列称为回滚指针，用于事务回滚，不在本文范畴）。这里的版本号并不是实际的时间值，而是系统版本号。每开始新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询每行记录的版本号进行比较。

每个事务又有自己的版本号，这样事务内执行CRUD操作时，就**通过版本号**的比较来达到数据版本控制的目的。



#### 版本链

在InnoDB引擎表中，它的**聚簇索引**记录中有**两个必要的隐藏列**：（所以说是基于索引的）

- **trx_id（上述说创建时的版本号和删除时的版本号是比较好理解的抽象）**：这个id用来存储的每次对某条聚簇索引记录进行修改的时候的事务id。

- **roll_pointer**：每次对哪条聚簇索引记录有修改的时候，都会把老版本写入undo日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的undo日志没有这个属性，因为它没有老版本)

**此时在undo日志中就存在版本链：**

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/810a19d8bc3eb135fbef89abe52630d7fd1f44b6.jpeg)



#### MVCC下InnoDB的增删查改

```mysql
CREATE TABLE testmvcc (
 id int(11) DEFAULT NULL,
 name varchar(11) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

1. **插入数据**：记录的版本号就是当前事务的版本号

   **insert into testmvcc values(1,"test");**

   **假设事务id为1**，那么插入后的数据行如下：

   ![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/aHR0cDovL3A5OC5wc3RhdHAuY29tL2xhcmdlL3BnYy1pbWFnZS8xNTM2Mjg2MzkyMDExMzMyZGM3OTk4MA.jpg)

2. **更新数据**：先标记旧的那行记录为已删除，并且删除版本号是事务版本号，然后插入一行新的记录的方式。

   **update table set name= 'new_value' where id=1;**

   ![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/aHR0cDovL3A5OC5wc3RhdHAuY29tL2xhcmdlL3BnYy1pbWFnZS8xNTM2Mjg2NDc5MDI2MmE4NTg5NmU1NQ.jpg)

3. **删除数据**：把事务版本号作为删除版本号

   **delete from table where id=1;**

   ![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/aHR0cDovL3A5LnBzdGF0cC5jb20vbGFyZ2UvcGdjLWltYWdlLzE1MzYyODY1MzI0MTUwZGZiYzdiZjY2.jpg)

4. **查询操作**：符合以下两个条件的记录才能被事务查询出来：

   - **删除版本号未指定或者大于当前事务版本号**，即查询事务开启后确保读取的行未被删除。

     (即上述事务id为2的事务查询时，依然能读取到事务id为3所删除的数据行)

   - 创建版本号 小于或者等于 当前事务版本号 

     就是说记录创建是在当前事务中（等于的情况）或者在当前事务启动之前的其他事物进行的insert。



#### ReadView

> **已提交读**和**可重复读**的区别就在于它们生成ReadView的策略不同。

ReadView中主要就是有个列表来存储我们系统中当前活跃着的读写事务，也就是begin了还未提交的事务。通过这个列表来判断记录的某个版本是否对当前事务可见。假设当前列表里的事务id为[80,100]。

- 如果你要访问的记录版本的事务id为50，比当前列表最小的id80小，那说明这个事务在之前就提交了，所以对当前活动的事务来说是可访问的。
- 如果你要访问的记录版本的事务id为70,发现此事务在列表id最大值和最小值之间，那就再判断一下是否在列表内，如果在那就说明此事务还未提交，所以版本不能被访问。如果不在那说明事务已经提交，所以版本可以被访问。
- 如果你要访问的记录版本的事务id为110，那比事务列表最大id100都大，那说明这个版本是在ReadView生成之后才发生的，所以不能被访问。

> 这些记录都是去版本链里面找的，先找最近记录，如果最近这一条记录事务id不符合条件，不可见的话，再去找上一个版本再比较当前事务的id和这个版本事务id看能不能访问，以此类推直到返回可见的版本或者结束。



**已提交读隔离级别下的事务在每次查询的开始都会生成一个独立的ReadView,而可重复读隔离级别则在第一次读的时候生成一个ReadView，之后的读都复用之前的ReadView。**





### 存储过程

> 像我们的函数一样，执行对应的操作实现功能，没有返回值

#### 优点

- 将代码封装起来，保存在数据库之中，供给供给主语言进行调用。
- 存储过程是一个预编译的代码块，执行效率高。
- 代替大量的T_SQL语句，可以降低网络通信量，提高通信效率。

#### 缺点

- 每种数据库的语法不同，难以维护。
- 业务逻辑实现放在数据库之上，难以迭代。



### 视图

> 基于数据库的一种虚表

- 为它提供数据的是select语句，可以理解为储存起来的sql语句
- 展示特定的数据，减少冗余，防止修改
- 可以将查询出来的数据进行封装，让我们更加专注于逻辑



### 存储引擎（表级别）

#### MyISAM

- 不提供事务的支持，不支持行级锁和外键，只支持表级锁。
- 占用内存较小。
- 对查询性能要求比较高的选择。
- 文件三个：.frm，.MYD，.MYI
- 索引结构为B+树，索引和数据分开，索引指向了文件地址，这是非聚集索引。
- 主键索引和辅助索引结构相同，在叶子结点存放的是索引和文件指针。



#### Innodb

- 支持事务，还支持行级锁和外键。
- 对表修改更新比较多，需要支持事务的选择。
- 文件两个：.frm，.ibd
- 索引结构为B+树，索引结构中储存的是实际的数据，为聚集索引。
- 主键索引在叶子结点存放的是索引和数据内容，而辅助索引存放的是索引和主键。



#### Memory

- 所有数据都在内存中，处理速度快，但是不够安全。
- 一般为了建立一个临时的表



### 数据库隔离级别

- **读未提交**（Read Uncommitted）

  读未提交，顾名思义，就是可以**读到未提交的内容**。

  因此，在这种隔离级别下，**查询是不会加锁的**，也由于查询的不加锁，所以这种隔离级别的一致性是最差的，可能会产生“脏读”、“不可重复读”、“幻读”。

  

- **读提交**（Read Committed）

  只能**读到已经提交了**的内容

  这是各种系统中最常用的一种隔离级别，也是**SQL Server**和**Oracle**的默认隔离级别。这种隔离级别能够有效的避免脏读。

  读不加锁，通过”快照读“进行。



- **可重复读**（Repeated Read）

  **Mysql**的默认隔离级别。

  在这个级别下，普通的查询同样是使用的**“快照读”**，但是，和“读提交”不同的是，当事务启动时，就**不允许进行“修改**操作（Update）”了，而“不可重复读”恰恰是因为两次读取之间进行了数据的修改，因此，“可重复读”能够有效的避免“不可重复读”，但却避免不了“幻读”，因为幻读是由于“插入或者删除操作（Insert or Delete）”而产生的



- **串行化**（Serializable）

这是数据库最高的隔离级别，这种级别下，事务“串行化顺序执行”，也就是一个一个排队执行。

这种级别下，“脏读”、“不可重复读”、“幻读”都可以被避免，但是执行**效率奇差**，性能开销也最大，所以基本没人会用。



### 数据库优化

#### 1. sql语句上的优化

- **使用最有效率的表名顺序。**自右向左处理from后面的表，如表之间无关系，则把数据少的放在右边，如果有关，把引用最多的放在右边。
- **where中条件的连接顺序。**自右向左处理，所以连接操作应该进来放在左边。
- **查询语句避免使用*号。**
- 删除全表内容用**truncate**代替**delete**，插入数据也同时插入而不是一条一条插。
- 尽量使用**数字类型代替字符型**。
- 尽量要用**可变长度代替定长**，减少存储空间。
- 善于区分使用**in**和**exist**。**in**主驱动在主select语句，而**exist**主驱动在从select语句。

#### 2. 索引

- **使用场景：**频繁查询操作，较少的插入更新。where语句条件，不能有or，或者是唯一的那几个值。
- **索引失效的场景（最左匹配）：**
  - 带有**<>**或者**!=**
  - 避免**or**，尽量使用**union all**连接
  - 带有**null值**会造成全局扫描
  - where子句中进行**运算**或者**函数操作**
  - 模糊查询，以通配符开始
  - 如果是复合索引，最左一个要匹配上

#### 3. 分表

#### 4. 读写分离

#### 5. 缓存



### 主从复制原理

#### 概念

Mysql 主从复制是指数据可以从一个Mysql数据库服务器**主节点复制到一个或多个从节点**。Mysql 默认采用**异步复制**方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。

#### 主要用途

- **读写分离**
  在开发工作中，有时候会遇见某个sql 语句需要锁表，导致暂时不能使用读的服务，这样就会影响现有业务，使用主从复制，让**主库负责写，从库负责读**，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。
- **数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换**
- **高可用HA** 
- **架构扩展**
  随着系统中业务访问量的增大，如果是单机部署数据库，就会导致I/O访问频率过高。有了主从复制，增加多个数据存储节点，将**负载分布在多个从节点**上，**降低单机磁盘I/O访问的频率**，提高单个机器的I/O性能。

#### 主从形式

- **一主一从。**
- **一主多从。**提高系统的读能力。
- **多主一从。**可以将数据库备份到一个储存性能比较好的服务器上。
- **双主复制。**双主复制，也就是互做主从复制，每个master既是master，又是另外一台服务器的slave。这样任何一方所做的变更，都会通过复制应用到另外一方的数据库中。
- **级联复制。**级联复制模式下，部分slave的数据同步不连接主节点，而是连接从节点。因为如果主节点有太多的从节点，就会损耗一部分性能用于replication，那么我们可以让3~5个从节点连接主节点，其它从节点作为二级或者三级与从节点连接，这样不仅可以缓解主节点的压力，并且对数据一致性没有负面影响。

![](https://gitee.com/wextree/Wex_imgs/raw/master/img/v2-be1bf038ce647dc46bf5abe5b4c48ad7_720w.jpg)

#### 主从复制原理

Mysql主从复制涉及到**三个线程**，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点，如下图所示:

![](https://gitee.com/wextree/Wex_imgs/raw/master/img/v2-1b0c3f31bd398c39b9e0930059b0ca24_720w.jpg)

当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个**binary log dump** 进程，而每个从节点都有自己的**I/O进程**，**SQL进程**。从节点用**两个线程将从主库拉取更新和执行分成独立**的任务，这样在执行同步数据任务的时候，**不会降低读操作的性能**。

-  **主节点 binary log dump 线程**
   当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送**bin-log**的内容。在读取bin-log中的操作时，此线程会对主节点上的**bin-log加锁**，当**读取完成**，甚至在**发动给从节点之前**，锁会被释放。
-  **从节点I/O线程**
   当从节点上执行`start slave`命令之后，从节点会创建一个**I/O线程**用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地**relay-log**中。
-  **从节点SQL线程**
   SQL线程负责读取**relay log**中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。

#### 主从复制过程

![](https://gitee.com/wextree/Wex_imgs/raw/master/img/v2-17a1d089c3266a59b5d00d7bd055bed7_720w.jpg)

- 从节点上的I/O 进程连接主节点，并**请求从指定日志文件的指定位置**（或者从最开始的日志）之后的日志内容；
- 主节点接收到来自从节点的I/O请求后，通过负责复制的I/O进程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的**bin-log file 的以及bin-log position**；
- 从节点的I/O进程接收到内容后，将接收到的日志内容**更新到本机的relay log**中，并将读取到的binary log文件名和位置保存到master-info 文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；
- Slave 的 SQL线程**检测到relay-log 中新增加了内容**后，会将relay-log的内容解析成在祝节点上实际执行过的操作，并在本数据库中执行。

#### 主从复制模式

>   Failover 失效转移 
>   通俗地说，即当A无法为客户服务时，系统能够自动地切换，使B能够及时地顶上继续为客户提供服务，且客户感觉不到这个为他提供服务的对象已经更换。 
>   Failback 自动恢复 
>   在簇网络系统（有两台或多台服务器互联的网络）中，由于要某台服务器进行维修，需要网络资源和服务暂时重定向到备用系统。在此之后将网络资源和服务器恢复为由原始主机提供的过程，称为自动恢复。  

- **异步模式**
  这种模式下，主节点不会主动push bin log到从节点，这样有可能导致failover的情况下，也许从节点没有即时地将最新的bin log同步到本地。

- **半同步模式**

  这种模式下主节点只需要接收到其中一台从节点的返回信息，就会commit；否则需要等待直到超时时间然后切换成异步模式再提交；这样做的目的可以使主从数据库的数据延迟缩小，可以提高数据安全性，确保了事务提交后，binlog至少传输到了一个从节点上，不能保证从节点将此事务更新到db中。性能上会有一定的降低，响应时间会变长。

- **全同步模式：**

  全同步模式是指主节点和从节点全部执行了commit并确认才会向客户端返回成功。

  - **binlog记录格式：**

    Mysql 主从复制有三种方式：**基于SQL语句的复制**，**基于行的复制**，**混合模式复制**。对应的binlog文件的格式也有三种：**STATEMENT**，**ROW**，**MIXED**。

    - Statement-base Replication (SBR)就是记录sql语句在bin log中，Mysql 5.1.4 及之前的版本都是使用的这种复制格式。优点是只需要记录会修改数据的sql语句到binlog中，减少了binlog日质量，节约I/O，提高性能。缺点是在某些情况下，**会导致主从节点中数据不一致**（比如sleep(),now()等）。

    - Row-based Relication(RBR)是mysql master将SQL语句分解为基于Row更改的语句并记录在bin log中，也就是只**记录哪条数据被修改**了，修改成什么样。优点是不会出现某些特定情况下的存储过程、或者函数、或者trigger的调用或者触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是修改table的时候会让日志暴增,同时增加bin log同步时间。也不能通过bin log解析获取执行过的sql语句，**只能看到发生的data变更**。

    - Mixed-format Replication(MBR)，Mysql NDB cluster 7.3 和7.4 使用的MBR。是以上两种模式的混合，对于**一般的复制使用STATEMENT模式保存到binlog**，对于STATEMENT模式**无法复制的操作则使用ROW模式来保存**，Mysql会根据执行的SQL语句选择日志保存方式。

  - **GTID复制模式**

    @ 在传统的复制里面，当发生故障，需要主从切换，需要找到binlog和pos点，然后将主节点指向新的主节点，相对来说比较麻烦，也容易出错。在MySQL 5.6里面，不用再找binlog和pos点，我们只需要知道主节点的ip，端口，以及账号密码就行，因为复制是自动的，MySQL会通过内部机制GTID自动找点同步。
    @ 多线程复制（基于库），在MySQL 5.6以前的版本，slave的复制是单线程的。一个事件一个事件的读取应用。而master是并发写入的，所以延时是避免不了的。唯一有效的方法是把多个库放在多台slave，这样又有点浪费服务器。在MySQL 5.6里面，我们可以把多个表放在多个库，这样就可以使用多线程复制。

  - **基于GTID复制实现的工作原理**

    - 主节点更新数据时，会在事务前产生GTID，一起记录到binlog日志中。
    - 从节点的I/O线程将变更的bin log，写入到本地的relay log中。
    - SQL线程从relay log中获取GTID，然后对比本地binlog是否有记录（所以MySQL从节点必须要开启binary log）。
    - 如果有记录，说明该GTID的事务已经执行，从节点会忽略。
    - 如果没有记录，从节点就会从relay log中执行该GTID的事务，并记录到bin log。
    - 在解析过程中会判断是否有主键，如果没有就用二级索引，如果有就用全部扫描。





## 面试问题

> 参考文档：https://juejin.im/post/6844904127047139335

### 1. 为什么要使用数据库

- **数据保存在内存**
  - 优点： 存取速度快
  - 缺点： 数据不能永久保存

- **数据保存在文件**
  - 优点： 数据永久保存
  - 缺点：1、速度比内存操作慢，频繁的IO操作。2、查询数据不方便

- **数据保存在数据库**
  - 数据永久保存
  - 使用SQL语句，查询方便效率高。
  - 管理数据方便




### 2. mysql有关权限的表都有哪几个

- **user：**允许连接到服务器的用户信息，里面的权限是全级的。
- **db：**记录各个账号在各个数据库上的操作权限
- **table_priv：**记录在数据表级的操作权限
- **columns_priv：**记录在数据列级的操作权限
- **host：**根据db表上对给定主机上的数据库级别进行更加细致的控制，不受grant和revoke语句的影响



### 3. 数据库经常使用的函数

- **count(*/column)**：返回行数

- **sum(column)**： 返回指定列中唯一值的和

- **max(column)**：返回指定列或表达式中的数值最大值

- **min(column)**：返回指定列或表达式中的数值最小值

- **avg(column)**：返回指定列或表达式中的数值平均值

- **date（Expression）**: 返回指定表达式代表的日期值



### 4. mysql有哪些数据类型

| 分类             | 类型名称     | 说明                                                         |
| :--------------- | ------------ | ------------------------------------------------------------ |
| 整数类型         | tinyInt      | 很小的整数(8位二进制)                                        |
| 整数类型         | smallint     | 小的整数(16位二进制)                                         |
| 整数类型         | mediumint    | 中等大小的整数(24位二进制)                                   |
| 整数类型         | int(integer) | 普通大小的整数(32位二进制)                                   |
| 小数类型         | float        | 单精度浮点数                                                 |
| 小数类型         | double       | 双精度浮点数                                                 |
| 小数类型         | decimal(m,d) | 压缩严格的定点数                                             |
| 日期类型         | year         | YYYY 1901~2155                                               |
| 日期类型         | time         | HH:MM:SS -838:59:59~838:59:59                                |
| 日期类型         | date         | YYYY-MM-DD 1000-01-01~9999-12-3                              |
| 日期类型         | datetime     | YYYY-MM-DD HH:MM:SS 1000-01-01 00:00:00~ 9999-12-31 23:59:59 |
| 日期类型         | timestamp    | YYYY-MM-DD HH:MM:SS 19700101 00:00:01 UTC~2038-01-19 03:14:07UTC |
| 文本、二进制类型 | CHAR(M)      | M为0~255之间的整数                                           |
| 文本、二进制类型 | VARCHAR(M)   | M为0~65535之间的整数                                         |
| 文本、二进制类型 | TINYBLOB     | 允许长度0~255字节                                            |
| 文本、二进制类型 | BLOB         | 允许长度0~65535字节                                          |
| 文本、二进制类型 | MEDIUMBLOB   | 允许长度0~167772150字节                                      |
| 文本、二进制类型 | LONGBLOB     | 允许长度0~4294967295字节                                     |
| 文本、二进制类型 | TINYTEXT     | 允许长度0~255字节                                            |
| 文本、二进制类型 | TEXT         | 允许长度0~65535字节                                          |
| 文本、二进制类型 | MEDIUMTEXT   | 允许长度0~167772150字节                                      |
| 文本、二进制类型 | LONGTEXT     | 允许长度0~4294967295字节                                     |
| 文本、二进制类型 | VARBINARY(M) | 允许长度0~M个字节的变长字节字符串                            |
| 文本、二进制类型 | BINARY(M)    | 允许长度0~M个字节的定长字节字符串                            |

1. **整数类型**，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。
    `长度`：整数类型可以被指定长度，例如：INT(11)表示长度为11的INT类型。长度在大多数场景是没有意义的，它**不会限制值的合法范围，只会影响显示字符的个数**，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。
    `例子`，假定类型设定为INT(5)，属性为UNSIGNED ZEROFILL，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。

2. **实数类型**，包括FLOAT、DOUBLE、DECIMAL。
    DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。
    而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。
    计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，**DECIMAL你可以理解成是用字符串进行处理。**

3. **字符串类型**，包括VARCHAR、CHAR、TEXT、BLOB
    VARCHAR用于存储可变长字符串，它比定长类型更节省空间。
    VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。
    VARCHAR存储的内容超出设置的长度时，内容会被截断。
    CHAR是定长的，根据定义的字符串长度分配足够的空间。
    CHAR会根据需要使用空格进行填充方便比较。
    CHAR适合存储很短的字符串，或者所有值都接近同一个长度。
    CHAR存储的内容超出设置的长度时，内容同样会被截断。

> **使用策略：**
>  对于经常变更的数据来说，CHAR比VARCHAR更好，因为**CHAR不容易产生碎片**。
>  对于**非常短**的列，CHAR比VARCHAR在存储空间上更有效率。
>  使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。
>  尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。



4. **枚举类型（ENUM**），把不重复的数据存储为一个预定义的集合。
    有时可以使用ENUM代替常用的字符串类型。
    **ENUM存储非常紧凑**，会把列表值压缩到一个或两个字节。
    ENUM在内部存储时，其实存的是整数。
    尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。
    排序是按照内部存储的整数

5. **日期和时间类型**，尽量使用timestamp，**空间效率高**于datetime，
    用整数保存时间戳通常不方便处理。
    如果需要存储微秒，可以使用bigint存储。


### 5. MySQL存储引擎MyISAM与InnoDB区别

存储引擎Storage engine：MySQL中的**数据、索引以及其他对象是如何存储的**，是一套**文件系统**的实现。

**常用的存储引擎**有以下：

- **Innodb引擎**：Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统。
- **MyIASM引擎**(原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。
- **MEMORY引擎**：所有的数据都在内存中，数据的处理速度快，但是安全性不高。



| 比较                                                         | MyISAM                                                       | Innodb                                                       |
| :----------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储结构                                                     | 每张表被存放在三个文件：frm-表格定义、MYD(MYData)-数据文件、MYI(MYIndex)-索引文件 | 所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB |
| 存储空间                                                     | MyISAM可被压缩，存储空间较小                                 | InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引 |
| 可移植性、备份及恢复                                         | 由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作 | 免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了 |
| 文件格式                                                     | 数据和索引是分别存储的，数据`.MYD`，索引`.MYI`               | 数据和索引是集中存储的，`.ibd`                               |
| 记录存储顺序                                                 | 按记录插入顺序保存                                           | 按主键大小有序插入                                           |
| 外键                                                         | 不支持                                                       | 支持                                                         |
| 事务                                                         | 不支持                                                       | 支持                                                         |
| 锁支持（锁是避免资源争用的一个机制，MySQL锁对用户几乎是透明的） | 表级锁定                                                     | 行级锁定、表级锁定，锁定力度小并发能力高                     |
| SELECT                                                       | MyISAM更优                                                   | --                                                           |
| INSERT、UPDATE、DELETE                                       | --                                                           | InnoDB更优                                                   |
| select count(*)                                              | myisam更快，因为myisam内部维护了一个计数器，可以直接调取。   |                                                              |
| 索引的实现方式                                               | B+树索引，myisam 是堆表                                      | B+树索引，Innodb 是索引组织表                                |
| 哈希索引                                                     | 不支持                                                       | 支持                                                         |
| 全文索引                                                     | 支持                                                         | 不支持                                                       |

> myisam使用的**堆组织表**(Heap Organize Table, HOT),没有聚集索引的概念,使用B-tree索引的存储格式，显示都是**随机顺序**。
> innodb表是**索引组织表**(Index Organized Table, IOT)，它的索引则是采用 **clustered index** 方式，因此主键会**按照顺序存储**，每次有记录有更新时，会重新整理更新其主键。因此无论是直接从 myisam 表转换过来的，还是后来插入的记录，显示时都会按照主键的顺序。



**区别：**

- InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。
- InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
- MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。
- InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。



### 6. InnoDB引擎的4大特性

**1. 插入缓冲（insert buffer)**

> 提升插入性能，**change buffering**是insert buffer的加强
>
> insertbuffer只针对insert有效，change buffering对insert、delete、update(delete+insert)、purge都有效

只对于**非聚集索引（非唯一）**的插入和更新有效，对于每一次的插入不是写到索引页中，而是先判断插入的非聚集索引页**是否在缓冲池**中，如果在则直接插入；若不在，则先放到Insert Buffer 中，再按照一定的频率进行合并操作，再写回disk。这样通常能将多个插入合并到一个操作中，目的还是为了减少随机IO带来性能损耗。（配合上**redoLog**可以实现一致性和持久化）

使用插入缓冲的条件：（因为涉及这两个索引就要回去数据库中查找是否重复）

- 非聚集索引
- 非唯一索引



**2. 二次写(double write)**

- **Doublewrite缓存**是位于**系统表空间的存储区域**，用来缓存InnoDB的数据页从innodb buffer pool中flush之后并**写入到数据文件之前**
- 所以当操作系统或者数据库进程在数据页写磁盘的过程中崩溃，Innodb可以在doublewrite缓存中找到数据页的备份而**用来执行crash恢复**。
- 数据页写入到doublewrite缓存的动作所需要的IO消耗要小于写入到数据文件的消耗，因为此写入操作会以一次大的连续块的方式写入

- 在应用（apply）重做日志前，用户需要一个**页的副本**，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是double write



**doublewrite组成：**

- **内存中**的doublewrite buffer,**大小2M**。
- **物理磁盘上共享表空间**中连续的128个页，即2个区（extend），**大小同样为2M**。

1. 对缓冲池的脏页进行刷新时，**不是直接写磁盘**，而是会通过**memcpy()函数**将脏页先复制到内存中的doublewrite buffer
2. 之后通过doublewrite 再**分两次**，**每次1M顺序**地写入共享表空间的物理磁盘上，在这个过程中，因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大。
3. 在完成doublewrite页的写入后，再将doublewrite buffer 中的页写入各个**表空间文件**中，此时的写入则是离散的。如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，innodb可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件，再应用重做日志。



**3.自适应哈希索引**

Adaptive Hash index属性使得InnoDB更像是内存数据库。

Innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热数据，建立哈希索引可以带来速度的提升

经常访问的二级索引数据会自动被生成到hash索引里面去(最近连续被访问三次的数据)，自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。
哈希（hash）是一种非常快的等值查找方法，在一般情况下这种查找的时间复杂度为O(1),即一般仅需要一次查找就能定位数据。而B+树的查找次数，取决于B+树的高度，在生产环境中，B+树的高度一般3-4层，故需要3-4次的查询。

innodb会监控对表上索引页的查询。如果观察到建立哈希索引可以带来速度提升，则自动建立哈希索引，称之为自适应哈希索引（Adaptive Hash Index，AHI）。
AHI有一个要求，就是对这个页的连续访问模式必须是一样的。



**4. 预读(read ahead)**

- InnoDB**在I/O的优化上**相对之前有着独特的预读机制，预读机制就是发起一个i/o请求，**异步**地在缓冲池中预先回迁若干页面，**预计将会用到回迁的页面**，这些请求在一个范围内引入所有页面。

- InnoDB以**64个page为一个extent**，而page和extent则是接下来要介绍的两种预读算法的**基本单位**。



1. 数据库发起数据请求，请求被提交到文件读取系统，**放入相关请求队列**中；

2. 读取进程从请求队列把请求取出，根据读取请求到相关的数据存储介质读取数据；
3. 返回数据，放入响应队列，最后数据库从响应队列中将数据取走，完成数据读取。

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/v2-a03d01072badadaba3156df8fb187ea7_r.jpg)



**相关流程**

接着进程继续处理请求队列，(如果数据库是全表扫描的话，数据读请求将会占满请求队列)，判断后面几个数据读请求的数据是否相邻，再根据**自身系统IO带宽处理量**，进行预读，进行读请求的合并处理，一次性读取多块数据放入响应队列中，再被数据库取走。(如此，一次物理读操作，实现多页数据读取，rrqm>0（# iostat -x），假设是4个读请求合并，则rrqm参数显示的就是4)

InnoDB使用两种预读算法来提高I/O性能：**线性预读（linear read-ahead）**和**随机预读（randomread-ahead）**

为了区分这两种预读的方式，我们可以**把线性预读放到以extent为单位，而随机预读放到以extent中的page为单位**。

线性预读着眼于将下一个extent提前读取到buffer pool中，而随机预读着眼于将当前extent中的剩余的page提前读取到buffer pool中。



### 7. 存储引擎选择

- 如果没有特别的需求，使用默认的`Innodb`即可。
- MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。
- Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。



### 8. 简述有哪些索引和作用

- 唯一索引：不允许有俩行具有相同的值

- 主键索引：为了保持数据库表与表之间的关系

- 聚集索引：表中行的物理顺序与键值的逻辑（索引）顺序相同。

- 非聚集索引：聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致

- 复合索引：在创建索引时，并不是只能对一列进行创建索引，可以与主键一样，讲多个组合为索引

- 全文索引： 全文索引为在字符串数据中进行复杂的词搜索提供有效支持



### 9. 创建索引的原则

- 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

- 较频繁作为查询条件的字段才去创建索引

- 更新频繁字段不适合创建索引

- 若是不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低)

- 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。

- 定义有外键的数据列一定要建立索引。

- 对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。

- 对于定义为text、image和bit的数据类型的列不要建立索引。



### 10. 创建索引的三种方式

**第一种方式：在执行CREATE TABLE时创建索引**

```mysql
CREATE TABLE user_index2 ( 
    id INT auto_increment PRIMARY KEY, 
    first_name VARCHAR (16), 
    last_name VARCHAR (16), 
    id_card VARCHAR (18), 
    information text, 
    KEY name (first_name, last_name), 
    FULLTEXT KEY (information), 
    UNIQUE KEY (id_card) 
);
```



**第二种方式：使用ALTER TABLE命令去增加索引**

```mysql
ALTER TABLE table_name ADD INDEX index_name (column_list);
```

- ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。
- 其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。
- 索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。



**第三种方式：使用CREATE INDEX命令创建**

```mysql
CREATE INDEX index_name ON table_name (column_list);
```

- CREATE INDEX可对表增加普通索引或UNIQUE索引。（但是，不能创建PRIMARY KEY索引）



> 删除索引：
>
> - 根据索引名删除普通索引、唯一索引、全文索引：`alter table 表名 drop KEY 索引名`
>
> - 删除主键索引：`alter table 表名 drop primary key`（因为主键只有一个）。这里值得注意的是，如果主键自增长，那么不能直接执行此操作（自增长依赖于主键索引）
> - 需要取消自增长再行删除



### 11. 百万级别或以上的数据如何删除

- 关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件（单独记录）,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。

1. 所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）
2. 然后删除其中无用数据（此过程需要不到两分钟）
3. 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。
4. 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。



### 12. 前缀索引

**语法：**`index(field(10))`，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。

**前提：**前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。

**实操的难度：**在于前缀截取的长度。

我们可以利用`select count(*)/count(distinct left(password,prefixLen));`，通过从调整`prefixLen`的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前`prefixLen`个字符几乎能确定唯一一条记录）



### 13. 事物的四大特性(ACID)介绍一下?

- **原子性：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；

- **一致性：** 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；

- **隔离性：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；

- **持久性：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。



### 14. 什么是脏读？幻读？不可重复读？

- **脏读(Drity Read)**：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。

- **不可重复读(Non-repeatable read)**：在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。

- **幻读(Phantom Read)**：在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。



### 15. 四个隔离级别

- **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。

- **READ-COMMITTED(读取已提交)：** （Oracle默认隔离级别）允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。

- **REPEATABLE-READ(可重复读)：** （MySQL默认隔离级别）。对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。

- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。

|     隔离级别     | 脏读 | 不可重复读 | 幻影读 |
| :--------------: | :--: | :--------: | :----: |
| READ-UNCOMMITTED |  √   |     √      |   √    |
|  READ-COMMITTED  |  ×   |     √      |   √    |
| REPEATABLE-READ  |  ×   |     ×      |   √    |
|   SERIALIZABLE   |  ×   |     ×      |   ×    |

> **注意：**
>
> - 这里需要注意的是：Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别
> - 事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。
> - 因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是**READ-COMMITTED(读取提交内容):**，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）**并不会有任何性能损失。
> - InnoDB 存储引擎在 **分布式事务** 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别。



### 16. 从锁的类别上分MySQL都有哪些锁呢？

- **共享锁:** 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁就是让多个线程同时获取一个锁。

- **排他锁:** 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排它锁也称作独占锁，一个锁在某一时刻只能被一个线程占有，其它线程必须等待锁被释放之后才可能获取到锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。



**隔离级别与锁的关系：**（主要是**共享锁**的加锁时间）

- 在Read Uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突
- 在Read Committed级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁；
- 在Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。
- SERIALIZABLE 是限制性最强的隔离级别，因为该级别**锁定整个范围的键**，并一直持有锁，直到事务完成。



### 17. 按照锁的粒度分数据库锁有哪些？锁机制与InnoDB锁算法

- 在关系型数据库中，可以按照**锁的粒度**把数据库锁分为**行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )**。
- **MyISAM和InnoDB存储引擎使用的锁：**
  - MyISAM采用表级锁(table-level locking)。
  - InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁

**行级锁，表级锁和页级锁对比**

- **行级锁** 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加**锁粒度最小**，但**加锁的开销也最大**。行级锁分为共享锁 和 排他锁。
  - 特点：开销大，加锁慢；**会出现死锁**；锁定粒度最小，发生**锁冲突的概率最低**，**并发度也最高**。
- **表级锁** 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。
  - 特点：开销小，加锁快；**不会出现死锁**；锁定粒度大，发出锁冲突的概率最高，**并发度最低**。
- **页级锁** 页级锁是MySQL中锁定粒度**介于行级锁和表级锁中间**的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。
  - 特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，**并发度一般**



### 18. InnoDB存储引擎的锁的算法有三种

- Record lock：单个行记录上的锁
- Gap lock：间隙锁，锁定一个范围，不包括记录本身
- Next-key lock：record+gap 锁定一个范围，包含记录本身

**相关知识点：**

1. innodb对于行的查询使用next-key lock
2. Next-locking keying为了解决Phantom Problem幻读问题
3. 当查询的索引含有唯一属性时，将next-key lock降级为record key
4. Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致**幻读**问题的产生
5. 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1



### 19. 数据库的乐观锁和悲观锁是什么？怎么实现的？

- 数据库管理系统（DBMS）中的并发控制的任务是**确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性**。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。

- **悲观锁**：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制

  ```mysql
  //核心SQL,主要靠for update
  select status from t_goods where id=1 for update;
  ```
  
- **乐观锁**：假设不会发生并发冲突，只在提交操作时**检查是否违反数据完整性**。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。

  ```mysql
  //核心SQL
  update table set x=x+1, version=version+1 where id=#{id} and version=#{version};
  ```

**两种锁的使用场景**

- 从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像**乐观锁适用于写比较少的情况下（多读场景）**，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。
- 但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以**一般多写的场景下用悲观锁就比较合适。**



### 20. 视图

**视图的特点如下:**

- 视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。
- 视图是由基本表(实表)产生的表(虚表)。
- 视图的建立和删除不影响基本表。
- 对视图内容的更新(添加，删除和修改)直接影响基本表。
- 当视图来自多个基本表时，不允许添加和删除数据。



**下面是视图的常见使用场景：**

- 重用SQL语句；
- 简化复杂的SQL操作。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；
- 使用表的组成部分而不是整个表；
- 保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；
- 更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。



**视图的优点：**

1. 查询简单化。视图能简化用户的操作
2. 数据安全性。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护
3. 逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性

**视图的缺点：**

1. 性能。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，即使是视图的一个简单查询，数据库也把它变成一个复杂的结合体，需要花费一定的时间。

2. 修改限制。当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改。事实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对于比较复杂的视图，可能是不可修改的

   这些视图有如下特征：

   1.有UNIQUE等集合操作符的视图。

   2.有GROUP BY子句的视图。

   3.有诸如AVG\SUM\MAX等聚合函数的视图。 

   4.使用DISTINCT关键字的视图。

   5.连接表的视图（其中有些例外）



### 21. 什么是触发器？触发器的使用场景有哪些？

- 触发器是用户定义在关系表上的一类由事件驱动的特殊的存储过程。触发器是指一段代码，当触发某个事件时，自动执行这些代码。

**使用场景**

- 可以通过数据库中的相关表实现级联更改。
- 实时监控某张表中的某个字段的更改而需要做出相应的处理。
- 例如可以生成某些业务的编号。
- 注意不要滥用，否则会造成数据库及应用程序的维护困难。
- 大家需要牢记以上基础知识点，重点是理解数据类型CHAR和VARCHAR的差异，表存储引擎InnoDB和MyISAM的区别。



### 22. MySQL触发器种类

- **Before Insert**
- **After Insert**
- **Before Update**
- **After Update**
- **Before Delete**
- **After Delete**



### 23. SQL语句分类

- **数据定义语言DDL**（Data Definition Language）CREATE，DROP，ALTER

  主要为以上操作 即对逻辑结构等有操作的，其中包括表结构，视图和索引。

- **数据查询语言DQL**（Data Query Language）SELECT

  这个较为好理解 即查询操作，以select关键字。各种简单查询，连接查询等 都属于DQL。

- **数据操纵语言DML**（Data Manipulation Language）INSERT，UPDATE，DELETE

  主要为以上操作 即对数据进行操作的，对应上面所说的查询操作 DQL与DML共同构建了多数初级程序员常用的增删改查操作。而查询是较为特殊的一种 被划分到DQL中。

- **数据控制功能DCL**（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK

  主要为以上操作 即对数据库安全性完整性等有操作的，可以简单的理解为权限控制等。



### 24. SQL 约束有哪几种？

- **NOT NULL**: 用于控制字段的内容一定不能为空（NULL）。

- **UNIQUE**: 控件字段内容不能重复，一个表允许有多个 Unique 约束。

- **PRIMARY KEY**: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。

- **FOREIGN KEY**: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。

- **CHECK**: 用于控制字段的值范围。



### 25. mysql中 in 和 exists 区别

mysql中的in语句是**把外表和内表作hash 连接**，而exists语句是**对外表作loop循环**，每次loop循环再对内表进行查询。

一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要**区分环境**的。

1. 如果查询的两个表大小相当，那么用in和exists差别不大。
2. 如果两个表中一个较小，一个是大表，则**子查询表大的用exists**，**子查询表小的用in**。
3. not in 和not exists：如果查询语句使用了not in，那么**内外表都进行全表扫描**，没有用到索引；而**not extsts的子查询依然能用到表上的索引**。所以无论那个表大，**用not exists都比not in要快。**



### 26. mysql中int(10)和char(10)以及varchar(10)的区别

- **int(10)**的10表示**显示**的数据的长度（配合上 **zerofill** 才有意义），不是存储数据的大小；
- **chart(10)和varchar(10)**的10表示**存储数据的大小**，即表示存储多少个字符。

- char(10)表示存储定长的10个字符，不足10个就用**空格补齐**，占用更多的存储空间

- varchar(10)表示存储10个变长的字符，存储多少个就是多少个，**空格也按一个字符存储**，这一点是和char(10)的空格不同的，char(10)的空格表示占位**不算一个字符**。



### 27. drop、delete与truncate的区别

- 三者都表示删除，但是三者有一些差别：

|   比较   |                  Delete                  |            Truncate            |                         Drop                         |
| :------: | :--------------------------------------: | :----------------------------: | :--------------------------------------------------: |
|   类型   |                 属于DML                  |            属于DDL             |                       属于DDL                        |
|   回滚   |                  可回滚                  |            不可回滚            |                       不可回滚                       |
| 删除内容 | 表结构还在，删除表的全部或者一部分数据行 | 表结构还在，删除表中的所有数据 | 从数据库中删除表，所有的数据行，索引和权限也会被删除 |
| 删除速度 |         删除速度慢，需要逐行删除         |           删除速度快           |                     删除速度最快                     |

- 因此，在不再需要一张表的时候，用drop；在想删除部分数据行时候，用delete；在保留表而删除所有数据的时候用truncate。



### 28. 说出一些数据库优化方面的经验?

1. 有外键约束的话会影响增删改的性能，如果应用程序可以保证数据库的完整性那就去除外键

2. Sql语句全部大写，特别是列名大写，因为数据库的机制是这样的，sql语句发送到数据库服务器，数据库首先就会把sql编译成大写在执行，如果一开始就编译成大写就不需要了把sql编译成大写这个步骤了

3. 如果应用程序可以保证数据库的完整性，可以不需要按照三大范式来设计数据库

4. 其实可以不必要创建很多索引，索引可以加快查询速度，但是索引会消耗磁盘空间

5. 如果是jdbc的话，使用PreparedStatement不使用Statement，来创建SQl，PreparedStatement的性能比Statement的速度要快，使用PreparedStatement对象SQL语句会预编译在此对象中，PreparedStatement对象可以多次高效的执行



### 29. Explain字段解释

| 列名          | 说明                                                         |
| ------------- | ------------------------------------------------------------ |
| id            | 执行编号，标识select所属的行。如果在语句中没子查询或关联查询，只有唯一的select，每行都将显示1。否则，内层的select语句一般会顺序编号，对应于其在原始语句中的位置 |
| select_type   | 显示本行是简单或复杂select。如果查询有任何复杂的子查询，则最外层标记为PRIMARY（DERIVED、UNION、UNION RESUlT） |
| table         | 访问引用哪个表（引用某个查询，如“derived3”）                 |
| type          | 数据访问/读取操作类型（ALL、index、range、ref、eq_ref、const/system、NULL） |
| possible_keys | 揭示哪一些索引可能有利于高效的查找                           |
| key           | 显示mysql决定采用哪个索引来优化查询                          |
| key_len       | 显示mysql在索引里使用的字节数                                |
| ref           | 显示了之前的表在key列记录的索引中查找值所用的列或常量        |
| rows          | 为了找到所需的行而需要读取的行数，估算值，不精确。通过把所有rows列值相乘，可粗略估算整个查询会检查的行数 |
| Extra         | 额外信息，如using index、filesort等                          |

**id**

id是用来顺序标识整个查询中SELELCT 语句的，在嵌套查询中id越大的语句越先执行。该值可能为NULL，如果这一行用来说明的是其他行的联合结果。



**select_type**

表示查询的类型

| 类型               | 说明                                                         |
| ------------------ | ------------------------------------------------------------ |
| simple             | 简单子查询，不包含子查询和union                              |
| primary            | 包含union或者子查询，最外层的部分标记为primary               |
| subquery           | 一般子查询中的子查询被标记为subquery，也就是位于select列表中的查询 |
| derived            | 派生表——该临时表是从子查询派生出来的，位于from中的子查询     |
| union              | 位于union中第二个及其以后的子查询被标记为union，第一个就被标记为primary如果是union位于from中则标记为derived |
| union result       | 用来从匿名临时表里检索结果的select被标记为union result       |
| dependent union    | 顾名思义，首先需要满足UNION的条件，及UNION中第二个以及后面的SELECT语句，同时该语句依赖外部的查询 |
| dependent subquery | 和DEPENDENT UNION相对UNION一样                               |



**table**

对应行正在访问哪一个表，表名或者别名

- 关联优化器会为查询选择关联顺序，左侧深度优先
- 当from中有子查询的时候，表名是derivedN的形式，N指向子查询，也就是explain结果中的下一列
- 当有union result的时候，表名是union 1,2等的形式，1,2表示参与union的query id

注意：MySQL对待这些表和普通表一样，但是这些“临时表”是没有任何索引的。



**type**

type显示的是访问类型，是较为重要的一个指标，结果值从好到坏依次是：
 system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL ，一般来说，得保证查询至少达到range级别，最好能达到ref。

| 类型   | 说明                                                         |
| ------ | ------------------------------------------------------------ |
| All    | 最坏的情况,全表扫描                                          |
| index  | 和全表扫描一样。只是扫描表的时候按照索引次序进行而不是行。主要优点就是避免了排序, 但是开销仍然非常大。如在Extra列看到Using index，说明正在使用覆盖索引，只扫描索引的数据，它比按索引次序全表扫描的开销要小很多 |
| range  | 范围扫描，一个有限制的索引扫描。key 列显示使用了哪个索引。当使用=、 <>、>、>=、<、<=、IS NULL、<=>、BETWEEN 或者 IN 操作符,用常量比较关键字列时,可以使用 range |
| ref    | 一种索引访问，它返回所有匹配某个单个值的行。此类索引访问只有当使用非唯一性索引或唯一性索引非唯一性前缀时才会发生。这个类型跟eq_ref不同的是，它用在关联操作只使用了索引的最左前缀，或者索引不是UNIQUE和PRIMARY KEY。ref可以用于使用=或<=>操作符的带索引的列。 |
| eq_ref | 最多只返回一条符合条件的记录。使用唯一性索引或主键查找时会发生 （高效） |
| const  | 当确定最多只会有一行匹配的时候，MySQL优化器会在查询前读取它而且只读取一次，因此非常快。当主键放入where子句时，mysql把这个查询转为一个常量（高效） |
| system | 这是const连接类型的一种特例，表仅有一行满足条件。            |
| Null   | 意味说mysql能在优化阶段分解查询语句，在执行阶段甚至用不到访问表或索引（高效） |



**possible_keys**

显示查询使用了哪些索引，表示该索引可以进行高效地查找，但是列出来的索引对于后续优化过程可能是没有用的



**key**

key列显示MySQL实际决定使用的键（索引）。如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。



**key_len**

key_len列显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。使用的索引的长度。在不损失精确性的情况下，长度越短越好 。



**ref**

ref列显示使用哪个列或常数与key一起从表中选择行。



**rows**

rows列显示MySQL认为它执行查询时必须检查的行数。注意这是一个预估值。



**Extra**

Extra是EXPLAIN输出中另外一个很重要的列，该列显示MySQL在查询过程中的一些详细信息，MySQL查询优化器执行查询的过程中对查询计划的重要补充信息。

| 类型                         | 说明                                                         |
| ---------------------------- | ------------------------------------------------------------ |
| Using filesort               | MySQL有两种方式可以生成有序的结果，通过排序操作或者使用索引，当Extra中出现了Using filesort 说明MySQL使用了后者，但注意虽然叫filesort但并不是说明就是用了文件来进行排序，只要可能排序都是在内存里完成的。大部分情况下利用索引排序更快，所以一般这时也要考虑优化查询了。使用文件完成排序操作，这是可能是ordery by，group by语句的结果，这可能是一个CPU密集型的过程，可以通过选择合适的索引来改进性能，用索引来为查询结果排序。 |
| Using temporary              | 用临时表保存中间结果，常用于GROUP BY 和 ORDER BY操作中，一般看到它说明查询需要优化了，就算避免不了临时表的使用也要尽量避免硬盘临时表的使用。 |
| Not exists                   | MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行， 就不再搜索了。 |
| Using index                  | 说明查询是覆盖了索引的，不需要读取数据文件，从索引树（索引文件）中即可获得信息。如果同时出现using where，表明索引被用来执行索引键值的查找，没有using where，表明索引用来读取数据而非执行查找动作。这是MySQL服务层完成的，但无需再回表查询记录。 |
| Using index condition        | 这是MySQL 5.6出来的新特性，叫做“索引条件推送”。简单说一点就是MySQL原来在索引上是不能执行如like这样的操作的，但是现在可以了，这样减少了不必要的IO操作，但是只能用在二级索引上。 |
| Using where                  | 使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。**注意**：Extra列出现Using where表示MySQL服务器将存储引擎返回服务层以后再应用WHERE条件过滤。 |
| Using join buffer            | 使用了连接缓存：**Block Nested Loop**，连接算法是块嵌套循环连接;**Batched Key Access**，连接算法是批量索引连接 |
| impossible where             | where子句的值总是false，不能用来获取任何元组                 |
| select tables optimized away | 在没有GROUP BY子句的情况下，基于索引优化MIN/MAX操作，或者对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 |
| distinct                     | 优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作 |



### 30. mysql 分页

- LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，**第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。**初始记录行的偏移量是 **0**(而不是 1)

  `SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15`

- 为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 **-1**：

  `SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last.`

- 如果只给定一个参数，它表示返回最大的记录行数目：

  `SELECT * FROM table LIMIT 5; //检索前 5 个记录行`

- 换句话说，LIMIT n 等价于 LIMIT 0,n。



### 31. 主键的设定

- 主键是数据库确保数据行在整张表**唯一性的保障**，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。

- 推荐使用**自增ID**，不要使用UUID。

  因为在InnoDB存储引擎中，**主键索引是作为聚簇索引存在**的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据**(按照顺序)**，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，会**造成非常多的数据插入，数据移动**，然后导致产生很多的内存碎片，进而造成插入性能的下降。

> 关于主键是聚簇索引，如果没有主键，InnoDB会选择一个唯一键来作为聚簇索引，如果没有唯一键，会生成一个隐式的主键。



### 32. SQL语句优化的一些方法

1. 对查询进行优化，应尽量避免全表扫描，首先应考虑**在 where 及 order by 涉及的列上建立索引**。

2. 应尽量**避免**在 where 子句中对字段**进行 null 值判断**，否则将导致引擎放弃使用索引而进行**全表扫描**，如：

```mysql
select id from t where num is null
-- 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：
select id from t where num=0
```

3. 应尽量避免在 where 子句中使用**!=或<>**操作符，否则引擎将放弃使用索引而进行全表扫描。

4. 应尽量避免在 where 子句中使用**or** 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：

```mysql
select id from t where num=10 or num=20
-- 可以这样查询：
select id from t where num=10 union all select id from t where num=20
```

5. **in 和 not in** 也要慎用，否则会导致全表扫描，如：

```mysql
select id from t where num in(1,2,3) 
-- 对于连续的数值，能用 between 就不要用 in 了：
select id from t where num between 1 and 3
```

6. 下面的查询也将导致全表扫描：select id from t where name like ‘%李%’若要提高效率，可以考虑全文检索。

7. 如果在 where 子句中**使用参数**，也会导致全表扫描。因为SQL只有**在运行时才会解析局部变量**，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：

```mysql
select id from t where num=@num
-- 可以改为强制查询使用索引：
select id from t with(index(索引名)) where num=@num
```

8. 应尽量避免在 where 子句中对字段进行**表达式操作**，这将导致引擎放弃使用索引而进行全表扫描。如：

```mysql
select id from t where num/2=100
-- 应改为:
select id from t where num=100*2
```

9. 应尽量避免在where子句中对字段进行**函数操作**，这将导致引擎放弃使用索引而进行全表扫描。如：

```mysql
select id from t where substring(name,1,3)=’abc’
-- name以abc开头的id应改为:
select id from t where name like ‘abc%’
```

10. 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。




### 33. 大表怎么优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？

当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：

1. **限定数据的范围：** 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。；
2. **读/写分离：** 经典的数据库拆分方案，主库负责写，从库负责读；
3. **缓存：** 使用MySQL的缓存，另外对重量级、更新少的数据可以考虑使用应用级别的缓存；



**还有就是通过分库分表的方式进行优化，主要有垂直分区、垂直分表和水平分区、水平分表**

> 分表是将一个大表按照一定的规则分解成多张具有独立存储空间的实体表，每个表都对应三个文件，MYD 数据文件，.MYI 索引文件，.frm 表结构文件。这些表可以分布在同一块磁盘上，也可以在不同的机器上。在应用访问数据库读写的时候根据事先定义好的规则得到对应的表名，然后去操作它。
>
> 分区和分表相似，都是按照规则分解表。不同在于分表将大表分解为若干个独立的实体表，而分区是将数据分段划分在多个位置存放，分区后，表还是一张表，但数据分散到各个分散的位置了。

**1、垂直分区**

- **根据数据库里面数据表的相关性进行拆分。** 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

- **简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。** 如下图所示，这样来说大家应该就更容易理解了。

- **垂直拆分的优点：** 可以使得行数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。

  **垂直拆分的缺点：** 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；

  ![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/171735c7259992ab.jpg)



**2、垂直分表**

- 把主键和一些列放在一个表，然后把主键和另外的列放在另一个表中

**适用场景**

1. 如果一个表中某些列常用，另外一些列不常用

2. 可以使数据行变小，一个数据页能存储更多数据，查询时减少I/O次数

**缺点**

- 有些分表的策略基于应用层的逻辑算法，一旦逻辑算法改变，整个分表逻辑都会改变，扩展性较差
- 对于应用层来说，逻辑算法增加开发成本
- 管理冗余列，查询所有数据需要join操作

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/171735c725b21e8e.jpg)



**3、水平分区**

- **保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。**

- 水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。

- 水品拆分可以支持非常大的数据量。需要注意的一点是:分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 **水平拆分最好分库** 。

- 水平拆分能够 **支持非常大的数据量存储，应用端改造也少**，但 **分片事务难以解决** ，跨界点Join性能较差，逻辑复杂。



**4、水平分表：**

- 表很大，分割后可以降低在查询时需要读的数据和索引的页数，同时也降低了索引的层数，提高查询次数

**适用场景**

- 1、表中的数据本身就有独立性，例如表中分表记录各个地区的数据或者不同时期的数据，特别是有些数据常用，有些不常用。
- 2、需要把数据存放在多个介质上。

**水平切分的缺点**

- 1、给应用增加复杂度，通常查询时需要多个表名，查询所有数据都需UNION操作
- 2、在许多数据库应用中，这种复杂度会超过它带来的优点，查询时会增加读一个索引层的磁盘次数

#### 

> **数据库分片的两种常见方案：**
>
> - **客户端代理：** **分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。** 当当网的 **Sharding-JDBC** 、阿里的TDDL是两种比较常用的实现。
> - **中间件代理：** **在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。** 我们现在谈的 **Mycat** 、360的Atlas、网易的DDB等等都是这种架构的实现。



### 34. 分库分表后面临的问题

- **事务支持** 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。

- **跨库join**

  只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 分库分表方案产品

- **跨节点的count,order by,group by以及聚合函数问题** 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。

- **数据迁移，容量规划，扩容等问题** 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。

- **ID问题**

- 一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略
  - UUID 使用UUID作主键是最简单的方案，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 **Twitter的分布式自增ID算法Snowflake** 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。

- **跨分片的排序分页问题**

  一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：

![](https://gitee.com/Wextree/Wex_imgs/raw/master/img/171735c750f5b2cc.jpg)









































