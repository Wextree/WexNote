# 计算机基础

## 计算机网络

![层次关系](imgs\五层体系结构.png)

### 各层协议的功能和结构

- **应用层：**直接为应用程序提供服务，位于体系结构中的最高。
  - DNS, HTTP, SMTP, IMAP, POP, DHCP, SNMP，FTP，TELNET
- **运输层：**负责两个主机中进程之间的通信，提供分用和复用功能。
  - TCP, UDP
- **网络层：**负责为网络上不同的主机提供通信服务，选取合适的路由。
  - IP, ICMP, IGMP, ARP, RIP, OSPF, BGP
- **链路层：**两个主机之间的数据传输，总是在一段一段的链路中。链路层负责接受IP数据报，封装成帧。
- **物理层：**传送比特流





### 什么是HTTP协议？

1. HTTP是超文本传输协议，是一种应用层的协议。
2. 它定义了浏览器如何向服务器请求对应文档，和服务器如何将文档传回浏览器。
3. 它是利用TCP/IP传输，保证文档的可靠交付。
4. 它是无连接，无状态的，无连接表示每次都只处理一个请求，无状态表示处理事务没有记忆能力。



### HTTP报文

#### 请求报文

>HTTP报文由方法、URI、HTTP版本、HTTP首部字段等部分组成

![http请求报文格式](imgs\1587869038(1).jpg)

- Accept: text/html,image/*    【浏览器告诉服务器，它支持的数据类型】
- Accept-Charset: ISO-8859-1    【浏览器告诉服务器，它支持哪种**字符集**】
- Accept-Encoding: gzip,compress 【浏览器告诉服务器，它支持的**压缩格式**】
- Accept-Language: en-us,zh-cn 【浏览器告诉服务器，它的语言环境】
- Host: www.it315.org:80【浏览器告诉服务器，它的想访问哪台主机】
- If-Modified-Since: Tue, 11 Jul 2000 18:23:51 GMT【浏览器告诉服务器，缓存数据的时间】
- Referer: http://www.it315.org/index.jsp【浏览器告诉服务器，客户机是从那个页面来的---**反盗链**】
- 8.User-Agent: Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0)【浏览器告诉服务器，浏览器的内核是什么】
- Cookie【浏览器告诉服务器，**带来的Cookie是什么**】
- Connection: close/Keep-Alive  【浏览器告诉服务器，请求完后是断开链接还是保持链接】
- Date: Tue, 11 Jul 2000 18:23:51 GMT【浏览器告诉服务器，请求的时间】

#### 响应报文

> 在响应中，HTTP报文由HTTP版本、状态码（数字和原因短语）、HTTP首部字段3部分组成

![http响应报文](imgs\1587869233(1).jpg)

- Location: http://www.it315.org/index.jsp 【服务器告诉浏览器**要跳转到哪个页面**】
- Server: apache tomcat【服务器告诉浏览器，服务器的型号是什么】
- Content-Encoding: gzip 【服务器告诉浏览器**数据压缩的格式**】
- Content-Length: 80 【服务器告诉浏览器回送数据的长度】
- Content-Language: zh-cn 【服务器告诉浏览器，服务器的语言环境】
- Content-Type: text/html; charset=GB2312 【服务器告诉浏览器，**回送数据的类型**】
- Last-Modified: Tue, 11 Jul 2000 18:23:51 GMT【服务器告诉浏览器该资源上次更新时间】
- Refresh: 1;url=http://www.it315.org【服务器告诉浏览器要**定时刷新**】
- Content-Disposition: attachment; filename=aaa.zip【服务器告诉浏览器**以下载方式打开数据**】
- Transfer-Encoding: chunked  【服务器告诉浏览器数据以分块方式回送】
- Set-Cookie: SS=Q0=5Lb_nQ; path=/search【服务器告诉浏览器要**保存Cookie**】
- Expires: -1【服务器告诉浏览器**不要设置缓存**】
- Cache-Control: no-cache  【服务器告诉浏览器**不要设置缓存**】
- Pragma: no-cache   【服务器告诉浏览器**不要设置缓存**】
- Connection: close/Keep-Alive   【服务器告诉浏览器连接方式】
- Date: Tue, 11 Jul 2000 18:23:51 GMT【服务器告诉浏览器回送数据的时间】



### HTTP & HTTPS

- HTTP的URL以`http://`开始，而HTTPS以`https://`开始
- HTTP无法加密，是不安全的，HTTPS是加密的，是安全的
- HTTP使用的是80端口，HTTPS使用的是443端口
- HTTP位于应用层，但是HTTPS安全传输机制是位于传输层
- HTTP不需要证书认证，但是HTTPS需要SSL证书认证



### URI和URL的区别

- **URI：**是uniform resource identifier，统一资源标识符，用来唯一的标识一个资源。
  - Web上可用的每种资源如HTML文档、图像、视频片段、程序等都是一个来URI来定位的
  - URI一般由三部组成：
  - ①访问资源的命名机制
  - ②存放资源的主机名
  - ③资源自身的名称，由路径表示，着重强调于资源。
- **URL：**是uniform resource locater，统一资源定位器，它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源
  - URL是Internet上用来描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上，特别是著名的Mosaic。
  - 采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。URL一般由三部组成：
  - ①协议(或称为服务方式)
  - ②存有该资源的主机IP地址(有时也包括端口号)
  - ③主机资源的具体地址。如目录和文件名等
- **URN：**是uniform resource name，统一资源命名，是通过名字来标识资源，比如mailto:java-net@java.sun.com。
  - URI是以一种抽象的，高层次概念定义统一资源标识，而URL和URN则是具体的资源标识的方式。URL和URN都是一种URI。笼统地说，每个 URL 都是 URI，但不一定每个 URI 都是 URL。这是因为 URI 还包括一个子类，即统一资源名称 (URN)，它命名资源但不指定如何定位资源。上面的 mailto、news 和 isbn URI 都是 URN 的示例。



### 常用的HTTP方法

- **GET：** 用于请求访问已经被URI（统一资源标识符）识别的资源，可以通过URL传参给服务器
- **POST：**用于传输信息给服务器，主要功能与GET方法类似，但一般推荐使用POST方式。
- **PUT：** 传输文件，报文主体中包含文件内容，保存到对应URI位置。
- **HEAD：** 获得报文首部，与GET方法类似，只是不返回报文主体，一般用于验证URI是否有效。
- **DELETE：**删除文件，与PUT方法相反，删除对应URI位置的文件。
- **OPTIONS：**查询相应URI支持的HTTP方法。



### HTTPS的工作原理

- 首先HTTP请求服务端生成证书，客户端对证书的有效期、合法性、域名是否与请求的域名一致、证书的公钥（RSA加密）等进行校验；
- 客户端如果校验通过后，就根据证书的公钥的有效， 生成随机数，随机数使用公钥进行加密（RSA加密）；
- 消息体产生的后，对它的摘要进行MD5（或者SHA1）算法加密，此时就得到了RSA签名；
- 发送给服务端，此时只有服务端（RSA私钥）能解密。
- 解密得到的随机数，再用AES加密，作为密钥（此时的密钥只有客户端和服务端知道）。



### HTTP 1.1 的新特性

- **默认持久化连接节省通信量**，如果客户端和服务端没有一方明确提出要断开TCP连接，那么就会一直保持，可以发送多次的HTTP请求。
- **管线化**，客户端可以发送多个请求，而不用等待响应。
- **断点续传**，利用HTTP消息头分块传输编码，然后实体主体分块传输。
- **错误状态响应码** ，在HTTP 1.1中新增了24个错误状态响应码



### TCP的流量控制和拥塞控制

#### 流量控制 ----滑动窗口协议

为避免发送者发送过快，接受者来不及接受的情况，导致分组丢失。这个有滑动窗口协议实现（连续ARQ）。主要原理是发送方从接收方发回的确认包中获取接受窗口的大小，以调整自己的发送窗口的大小。（可能死锁，设置定时器）

#### 拥塞控制

##### 慢开始

发送方维持一个拥塞窗口。为了探测网络的拥挤程度，一开始先设置比较小的窗口，然后每经历一次传输轮回（RTT），拥塞窗口大小就加倍，此时拥塞窗口的大小呈幂指数增长。

##### 拥塞避免

为避免慢开始时期的拥塞窗口增长过快，设定一个慢开始门限，如果拥塞窗口超过慢开始门限的大小，改用拥塞避免算法，拥塞窗口每经历一次轮回，大小加一。此时拥塞窗口从指数型增长变为线性增长。由于当前时代的传输比较稳定，出现网络阻塞的定义一般就是发生了超时重传。此时将慢开始门限设置为当前拥塞窗口的一半，然后把拥塞窗口设置为1，执行慢开始。

##### 快重传

快重传要求接受方发现有失序的报文段时要立刻发送确认，而不能等到自己要发送数据时才捎带确认。发送方只+收到三个重复确认就要立刻重传数据，而不用等待重传计时器时间到期。

##### 快恢复

当发送方收到三个连续确认包时，将慢开始门限设置为当前的一半，由于收到好几个确认包，所以判定现在的网络不会阻塞，所以将拥塞窗口设置为门限值，直接执行拥塞避免算法。



### HTTP常见状态码

| 状态码 |             响应类别             |             原因短语             |
| :----: | :------------------------------: | :------------------------------: |
|  1 XX  |  信息性状态码（Informational）   |        服务器正在处理请求        |
|  2 XX  |      成功状态码（Success）       |        请求已正常处理完毕        |
|  3 XX  |   重定向状态码（Redirection）    |    需要进行额外操作以完成请求    |
|  4 XX  | 客户端错误状态码（Client Error） | 客户端原因导致服务器无法处理请求 |
|  5 XX  | 服务器错误状态码（Server Error） |    服务器原因导致处理请求出错    |

|          状态码           |                 内容                 |
| :-----------------------: | :----------------------------------: |
|          200 OK           |           请求正常处理完毕           |
|      204 No Content       |   请求成功处理，没有实体的主体返回   |
|    206 Partial Content    |        GET范围请求已成功处理         |
|   301 Moved Permanently   |   永久重定向，资源已永久分配新URI    |
|         302 Found         |   临时重定向，资源已临时分配新URI    |
|       303 See Other       |   临时重定向，期望使用GET定向获取    |
|     304 Not Modified      |       发送的附带条件请求未满足       |
|  307 Temporary Redirect   |     临时重定向，POST不会变成GET      |
|      400 Bad Request      |      请求报文语法错误或参数错误      |
|     401 Unauthorized      |     需要通过HTTP认证，或认证失败     |
|       403 Forbidden       |            请求资源被拒绝            |
|       404 Not Found       | 无法找到请求资源（服务器无理由拒绝） |
| 500 Internal Server Error |       服务器故障或Web应用故障        |
|  503 Service Unavailable  |        服务器超负载或停机维护        |



### TCP保证可靠

- **三次握手**和**四次挥手**保证有效连接和释放。
- 将数据合理**分片**并且进行编号，有序地传输。
- 会将首部和数据部分进行**校验**，如果不通过会丢弃。
- **超时重传**，发送方未在一定时间内收到接受方的确认，将会重传。
- TCP会**丢弃重复**的包。
- **流量控制**和**拥塞控制**。



### TCP的11种状态

|     状态     |                             表示                             |
| :----------: | :----------------------------------------------------------: |
|    LISTEN    |              等待从任何远端TCP 和端口的连接请求              |
|   SYN_SENT   |          发送完一个连接请求后等待一个匹配的连接请求          |
| SYN_RECEIVED |   发送连接请求并且接收到匹配的连接请求以后等待连接请求确认   |
| ESTABLISHED  | 表示一个打开的连接，接收到的数据可以被投递给用户。连接的数据传输阶段的正常状态 |
|  FIN_WAIT_1  | 等待远端TCP 的连接终止请求，或者等待之前发送的连接终止请求的确认 |
|  FIN_WAIT_2  |                  等待远端TCP 的连接终止请求                  |
|  CLOSE_WAIT  |                  等待本地用户的连接终止请求                  |
|   CLOSING    |                等待远端TCP 的连接终止请求确认                |
|   LAST_ACK   | 等待先前发送给远端TCP 的连接终止请求的确认（包括它字节的连接终止请求的确认） |
|  TIME_WAIT   | 等待足够的时间过去以确保远端TCP 接收到它的连接终止请求的确认 |
|    CLOSED    |     不在连接状态（这是为方便描述假想的状态，实际不存在）     |

![TCP连接和释放](imgs\tcp连接与释放.png)

![TCP状态转换图](imgs\20160423144456154.png)

### TCP和UDP的区别

**我们从五个方面进行区分：**

- **可靠性：**TCP提供的是可靠传输，当发现数据丢失，收到确认后会进行重传。而UDP并没有确认和超时重传的概念，它提供的是不可靠的通信。
- **顺序：**TCP按顺序发送数据，并按照相同的顺序进行接收。如果顺序错误，还要重新排序交付给应用程序。而UDP无法预测接收的顺序。
- **连接：**TCP是一个重量级的连接，需要三次握手进行连接，也要四次挥手进行释放。并处理拥塞控制和可靠性。UDP是无连接的。
- **传输方式：**TCP读取数据作为字节流进行传输，而UDP是单独发送的数据报。
- **错误检测：**UDP协议支持通过校验和进行错误检测，但是当检测到错误时，将丢弃数据包。 没有尝试重新发送数据包以从该错误中恢复。TCP同时使用错误检测和错误恢复。 错误通过校验和检测，如果数据包错误，则接收方不会确认该错误，从而触发发送方重新发送。



###web页面请求过程

1. **DHCP配置主机信息**。如果此主机没有分配IP地址，就得先通过动态主机配置协议去获得一个临时的IP地址。
   1. 主机通过UDP发送广播到DHCP代理服务器。
   2. 代理服务器找到DHCP服务器，请求分配IP地址。
   3. DHCP根据信息向主机分配IP地址。
   4. 主机选择其中一个DHCP服务器发送确认，并且进行绑定，其他服务器发送不绑定。
2. **ARP解析MAC地址**。由于DHCP只能知道网关路由器的IP地址，为了获得物理地址，就必须使用ARP解析。
   1. 主机生成含有目的主机IP地址的ARP报文，然后进行广播。
   2. 当对应的路由器收到此报文，就记录该主机的MAC和IP地址，并把自己的MAC地址返回。
3. **DNS解析域名**。
   1. 主机发送DNS报文，由网关路由进行转发。
   2. 跟本地域名服务器进行递归查询。如果本地域名缓存里面有对应的IP地址，直接返回。
   3. 如果没有就对其他各个DNS服务器进行迭代查询。先向根，接着是顶级域名，最后是权限域名。
4. **HTTP请求页面**。
   1. 找到请求的域名的IP地址之后，就可以跟HTTP服务器建立TCP连接。
   2. 发送对应的请求报文。
   3. 服务器接收到请求报文，生成一个对应的响应报文，发送回浏览器。
   4. 浏览器解析响应报文，生成页面及渲染效果。



## 操作系统

### 什么是操作系统

1. 操作系统是管理计算机软件硬件的程序，是计算机系统的内核和基石。 
2. 操作系统实质上是运行在计算机上的软件。
3. 操作系统还给用户提供了一个与系统进行交互的界面。
4. 操作系统分内核和外核，外核是围绕着内核的应用程序，内核是操作硬件的程序，负责管理系统的内存，进程，设备，文件和网络系统等，是黑盒，是核心。、



### 系统调用

- **用户态：**用户态运行的进程可以获取用户的程序和数据。
- **系统态：**系统态的进程几乎可以反问所有的计算机资源。

但是我们的程序 一般都是运行在用户态，所以凡事有关系统态级别的资源的相关操作时候，比如文件，进程，内存，设备的管理和控制时候，就要通过系统调用的方式向系统发送服务请求，并交由系统代为完成。



### 进程状态转换图

![进程状态转换](imgs\d38202593012b457debbcd74994c6292.png)



### 进程和线程的区别

- 进程是资源管理的基本单位，线程是调度的基本单位
- 线程并发性，独立性比较高。
- 线程除自己栈空间和基本的寄存器，共用进程的资源。
- 一个进程执行过程，系统分配资源，也就是上下文，然后执行a小段，b小段，c小段等等，然后保存上下文，退出。
- 而内部粒度较小的a b c就是进程的内部线程，共享同个进程的资源。
- 资源具体就包括堆，静态变量，全局变量，文件等共用资源。
- 从JVM来说，多个线程共享进程的堆，方法区，而线程拥有自己的栈空间和程序计数器。
- 从操作系统来说，一个进程面对的是磁盘，因为每个进程拥有自己的虚拟内存。而线程更像是面对CPU去执行。



### 进程间的通信方式

> 通信相关：jianshu.com/p/c1015f5ffa74

- **管道：**半双工的方式。其实就是共享文件或者缓冲区的方式，严格限制先进先出。
- **信号：**信号是一种复杂的通信方式。通过将消息直接或者间接用原语的方式发送给另外一个进程。
- **消息队列：**是具有特定格式消息的链表，也是先进先出。但是它是放在内核里面，除非重启内核或者显式删除，不然不会消失。
- **信号量：**是一个计数器，用于控制多进程对于资源的访问。信号量在于控制进程的同步。
- **共享内存：**多个进程共享同一部分内存，可以看到内存中数据的更新。
- **套接字：**主要用于客户端喝服务器之间的通信。主要是通过TCP/IP对两个不同主机进程之间的通信。



### 进程调度

- **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
- **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。
- **高响应比优先调度：**考虑两个因素，包括等待时间和运行时间。运行时间越短，优先级越高，等待时间越长，优先级越高。



### 死锁

当资源是不可剥夺的，有两个或者两个以上的进程占有自己的资源，然后请求对方的资源，会导致进程无法向后推进。

**条件：**

- **互斥条件。**进程要求分配的资源是排他的，最多可以给一个进程去使用。
- **不可剥夺。**资源在被一个进程使用的时候，不可以被强行多走。
- **请求与保持。**进程占有自己的资源并请求其他资源。
- **循环等待。**存在一种进程资源的循环等待链。

**避免死锁：**

- **破坏互斥条件。**占有的资源先复制一份，当别的进程占用的时候就不会被阻塞。
- **破坏不可剥夺。**可以抢占，当进程需要一个资源，并且此资源被其他进程占有，可以抢占它的资源来使用。
- **破坏请求与保持。**在自己请求的资源缺少时，自动放弃自己持有的资源。
- **破坏循环等待。**资源指定获取顺序，所有进程都要按照一定顺序去获取资源，就不会造成环。



### 动态内存分配

- **首次适应算法：**
  - 优点： 该算法倾向于使用内存中低地址部分的空闲区，在高地址部分的空闲区很少被利用，从而保留了高地址部分的大空闲区。显然为以后到达的大作业分配大的内存空间创造了条件
  - 缺点：低地址部分不断被划分，留下许多难以利用、很小的空闲区，而每次查找又都从低地址部分开始，会增加查找的开销
- **最坏适应算法：**
  - 优点：给文件分配分区后剩下的空闲区不至于太小，产生碎片的几率最小，对中小型文件分配分区操作有利。
  - 缺点：使存储器中缺乏大的空闲区，对大型文件的分区分配不利。
- **最佳适应算法：**
  - 优点：每次分配给文件的都是最合适该文件大小的分区。
  - 缺点：内存中留下许多难以利用的小的空闲区。



### 内存管理机制

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**

1. **块式管理** ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
2. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段页式管理机制** ：段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。



### 分页和分段有什么共同点和不同点

1. 共同点：
   - 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
   - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
2. 区别：
   - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
   - 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。



### 快表和多级页表

#### 快表

为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把块表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

#### 多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。



### 虚拟内存

虚拟内存是一种内存的管理技术。它定义了一个连续的内存空间，并把内存扩展到了硬盘空间。它使得应用程序以为它拥有的是一大片连续的内存资源，但其实是分散的内存碎片，并且把部分暂时存储在外部的硬盘中。

#### 作用

- **虚拟内存作为缓存的工具。**
- **虚拟内存作为管理内存的工具。**
- **虚拟内存作为内存保护的工具。**

#### 实现

1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。

2. **请求分段存储管理** ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。

3. **请求段页式存储管理**

    

### 虚拟存储器

基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——**虚拟存储器**



### 局部性原理

我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。



### 页面置换算法

- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Currently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。



